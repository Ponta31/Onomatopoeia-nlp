{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79f9a54b-c6e2-4089-b850-4fe2f5ce4fc2",
   "metadata": {},
   "source": [
    "<h1>Japanese Onomatopoeia Paraphraser</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d6bcb7-a17a-4bb2-a7d6-549cfbd12b01",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "A. Corpus for Japanese including onomatopoeia\n",
    "- https://huggingface.co/datasets/oscar-corpus/OSCAR-2201\n",
    "\n",
    "B. Article for onomatopoeia list\n",
    "- https://www.tufs.ac.jp/common/fs/ilr/contents/ronshuu/26/jilr26_Article_Huang.pdf\n",
    "\n",
    "C. Onomatopoeia website\n",
    "- https://www2.ninjal.ac.jp/Onomatope/50_on/gatagata.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c0a4c9c-6a34-45e6-9097-0a5da1b8f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download libraries\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from gensim.models import Word2Vec\n",
    "import MeCab\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0243f3b-c3e3-456d-8779-3d64a0e20341",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#OnomatoParaphraser\n",
    "\n",
    "class OnomatoParaphraser:\n",
    "    #initialize \n",
    "    #The tools I would need are \"tokens and POS\" to look into the original sentence \n",
    "    #                           \"onomatope list\" that I found in an article\n",
    "    #                           \"Word2Vec model\" \n",
    "    def __init__(self, onomatope_path, additional_path):\n",
    "        self.mecab = MeCab.Tagger(\"--rcfile=/opt/homebrew/etc/mecabrc\") \n",
    "        self.word2vec_model = None\n",
    "\n",
    "        with open(onomatope_path, 'r', encoding='utf-8') as f:\n",
    "            onomatope_lines = f.readlines()\n",
    "            \n",
    "        self.onomatope_list = []\n",
    "        for line in onomatope_lines:\n",
    "            onomatopes = line.strip().split()\n",
    "            self.onomatope_list.extend(onomatopes)\n",
    "\n",
    "        self.onomatope_list = list(set(self.onomatope_list))\n",
    "        print(f\"Loaded {len(self.onomatope_list)} onomatopoeia from the list\")\n",
    "                \n",
    "        with open(additional_path, 'r', encoding='utf-8') as f:\n",
    "            additional_onoma_sentences = f.readlines()\n",
    "\n",
    "        self.additional_onoma_sentences = [line.strip().strip(',') for line in additional_onoma_sentences if line.strip()]\n",
    "        print(f\"Loaded {len(self.additional_onoma_sentences)} additional onomatopoeia sentences\")\n",
    "\n",
    "    \n",
    "    #Mecab output format\n",
    "    #表層形\\t品詞,品詞細分類1,品詞細分類2,品詞細分類3,活用型,活用形,原形,読み,発音\n",
    "\n",
    "\n",
    "    \n",
    "    #Function to tokenize Japanese text with MeCab\n",
    "    def tokenize_text(self, text):\n",
    "        parsed_text = self.mecab.parse(text)\n",
    "        lines = parsed_text.split('\\n')\n",
    "        tokens = []\n",
    "\n",
    "        for line in lines:\n",
    "            if line == 'EOS' or line == '':\n",
    "                continue\n",
    "            parts = line.split('\\t')\n",
    "            if len(parts) >= 2:\n",
    "                tokens.append(parts[0])\n",
    "\n",
    "        return tokens\n",
    "\n",
    "    \n",
    "\n",
    "    #Analyze POS because depending on POS, onomatope gets different suffix\n",
    "    def analyze_sentence(self, sentence):\n",
    "        mecab_result = self.mecab.parse(sentence)\n",
    "        lines = mecab_result.split('\\n')\n",
    "\n",
    "        words = []\n",
    "        POS_tags = []\n",
    "        \n",
    "        for line in lines:\n",
    "            if line == 'EOS' or line == '':\n",
    "                continue\n",
    "            parts = line.split('\\t')\n",
    "            if len(parts) >= 2:\n",
    "                word = parts[0]\n",
    "                pos = parts[1].split(',')[0] #mecab.parse includes several information, and the first one is POS\n",
    "\n",
    "                words.append(word)\n",
    "                POS_tags.append(pos)\n",
    "        \n",
    "\n",
    "        return list(zip(words, POS_tags))\n",
    "        \n",
    "\n",
    " #load Japanese texts from the corpus\n",
    "    def load_dataset(self, max_sample):\n",
    "\n",
    "        print(f\"loading corpus dataset, max={max_sample}\")\n",
    "\n",
    "        dataset = load_dataset(\"oscar-corpus/OSCAR-2301\",\n",
    "                               language=\"ja\",\n",
    "                               streaming=True,\n",
    "                               split=\"train\",\n",
    "                              )\n",
    "        \n",
    "        \n",
    "        #RegEx to remove some symbols\n",
    "        symbol_pattern = re.compile(r'[■□※●○\\{\\}【】\\*]+')\n",
    "        \n",
    "        #save Japanese sentences\n",
    "        JP_sentences = []\n",
    "        count = 0\n",
    "\n",
    "        for sample in dataset:\n",
    "\n",
    "            #The corpus is Dict[\"id\":___, \"text\":___]\n",
    "            text = sample[\"text\"] \n",
    "\n",
    "            #I want to split with \\n and '。'\n",
    "            lines = text.split('\\n')\n",
    "            \n",
    "            for line in lines:\n",
    "                sentences = line.split('。')\n",
    "\n",
    "            #if the sentence has a symbol, I will not use it. Go to next sentence\n",
    "            for sentence in sentences:\n",
    "                if symbol_pattern.search(sentence):\n",
    "                    continue\n",
    "                \n",
    "            #if the sentence is too short or too long, should be removed\n",
    "                if 10 <= len(sentence) <= 140 and sentence.strip():\n",
    "                    JP_sentences.append(sentence)\n",
    "                    count += 1\n",
    "\n",
    "                    if count >= max_sample:\n",
    "                        print(f\"Loaded {len(JP_sentences)} sentences\")\n",
    "                        return JP_sentences\n",
    "\n",
    " \n",
    "        print(f\"Loaded {len(JP_sentences)} sentences from corpus\")\n",
    "        return JP_sentences\n",
    "\n",
    "        \n",
    "                    \n",
    "\n",
    "\n",
    "    \n",
    "    #tokenize sentences as preparation for the word2vec model\n",
    "    def prepare_data_word2vec(self, training_sentences, max_sentences):\n",
    "        print(\"preparing data for word2vec\")\n",
    "\n",
    "        #I want to make tokenized_sentences list and count the number of sentence\n",
    "        tokenized_sentences = []\n",
    "        count = 0\n",
    "\n",
    "        #if the number of sentence is over, should be break\n",
    "        for sentence in training_sentences:\n",
    "            if count >= max_sentences:\n",
    "                break\n",
    "\n",
    "            #tokenize text and add to tokenized_sentences list\n",
    "            tokens = self.tokenize_text(sentence)\n",
    "            tokenized_sentences.append(tokens)\n",
    "            count += 1\n",
    "\n",
    "        print(f\"Completed preparation. The number of sentence for word2vec: {count}\")\n",
    "        return tokenized_sentences\n",
    "        \n",
    "    \n",
    "    #train word2vec\n",
    "    def train_word2vec(self, tokenized_sentences):\n",
    "        print(\"Training Word2Vec\")\n",
    "\n",
    "        self.word2vec_model = Word2Vec(\n",
    "            sentences=tokenized_sentences,\n",
    "            vector_size=100,\n",
    "            window=5,\n",
    "            min_count=1,\n",
    "            sg=1, #skip_gram\n",
    "            epochs=10\n",
    "        )\n",
    "\n",
    "        print(f\"completed training word2vec model with {len(tokenized_sentences)} sentences\")\n",
    "       \n",
    "        #if the onomatope in my list is not in the word2vec model, \n",
    "        #adding random vector to the model for the onomatope\n",
    "        \n",
    "        onoma_in_vocab = 0\n",
    "        onoma_added = 0\n",
    "\n",
    "        new_vectors = []\n",
    "        new_words = []\n",
    "        \n",
    "        for onomatope in self.onomatope_list:\n",
    "            if onomatope in self.word2vec_model.wv:\n",
    "                onoma_in_vocab +=1\n",
    "            else:\n",
    "                random_vector = np.random.uniform(-0.25, 0.25, size=self.word2vec_model.vector_size)\n",
    "                new_words.append(onomatope)\n",
    "                new_vectors.append(random_vector)\n",
    "                onoma_added += 1\n",
    "\n",
    "        if new_words:\n",
    "            self.word2vec_model.wv.add_vectors(new_words, new_vectors)\n",
    "        \n",
    "        print(f\"onomatope in word2vec vocab: {onoma_in_vocab}, onomatope random vector added:{onoma_added}\")\n",
    "\n",
    "        return self.word2vec_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #using the vectors from word2Vec, find similar onomatopoeias for the word\n",
    "    def find_similar_onomatope(self, word, top_n=5):\n",
    "\n",
    "        if word not in self.word2vec_model.wv:\n",
    "            print(f\"'{word}' is not in the vocabulary.\")\n",
    "            return []\n",
    "        \n",
    "        #extract similarity of word from sentence and onomatope from onomatope list in word2vec\n",
    "        similarities = []\n",
    "        for onoma in self.onomatope_list:\n",
    "            if onoma in self.word2vec_model.wv:\n",
    "                sim = self.word2vec_model.wv.similarity(word, onoma)\n",
    "                similarities.append((onoma, sim))\n",
    "\n",
    "                \n",
    "        #sort from high score\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        return similarities[:top_n]\n",
    "\n",
    "\n",
    "    #paraphrase the sentence\n",
    "    def paraphrase_sentence(self, sentence):\n",
    "        #analyze the sentence\n",
    "        analyzed_sentence = self.analyze_sentence(sentence)\n",
    "\n",
    "        #paraphrased result [original sentence;__, new sentence:__, similarity:__]\n",
    "        paraphrased_result = []\n",
    "\n",
    "        #Conditions\n",
    "        #1. If the sentence contains all '副詞', '形容詞', and '動詞' in this order, paraphrase the  '形容詞'.\n",
    "        #2. If the sentence contains '副詞' and '動詞' in this order, paraphrase the  '動詞'.\n",
    "        #3. If the sentence contains '形容詞' without '動詞', paraphrase the '形容詞'.\n",
    "\n",
    "        #The method has not yet found the POS\n",
    "        adv_pos = -1\n",
    "        adj_pos = -1\n",
    "        v_pos = -1\n",
    "\n",
    "        #find the index of the POS\n",
    "        for i, (word, pos) in enumerate(analyzed_sentence):\n",
    "            if pos == '副詞':\n",
    "                if adv_pos == -1:\n",
    "                    adv_pos = i\n",
    "            elif pos == '形容詞':\n",
    "                if adj_pos == -1:\n",
    "                    adj_pos = i\n",
    "            elif pos == '動詞':\n",
    "                if v_pos == -1:\n",
    "                    v_pos = i\n",
    "\n",
    "        #1. If the sentence contains all '副詞', '形容詞', and '動詞' in this order, paraphrase the  '形容詞'.\n",
    "        if (\n",
    "            adv_pos != -1 and\n",
    "            adj_pos != -1 and\n",
    "            v_pos != -1 and\n",
    "            adv_pos +1 == adj_pos and\n",
    "            adj_pos +1 == v_pos\n",
    "        ):\n",
    "            target_pos = adj_pos\n",
    "            target_word, pos = analyzed_sentence[target_pos]\n",
    "\n",
    "        #2. If the sentence contains '副詞' and '動詞' in this order, paraphrase the  '動詞'.\n",
    "        elif adv_pos != -1 and v_pos != -1 and adv_pos +1 == v_pos:\n",
    "            target_pos = v_pos\n",
    "            target_word, pos = analyzed_sentence[target_pos]\n",
    "\n",
    "        #3. If the sentence contains '形容詞' without '動詞', paraphrase the '形容詞'.\n",
    "        elif adj_pos != -1 and v_pos == -1:\n",
    "            target_pos = adj_pos\n",
    "            target_word, pos = analyzed_sentence[target_pos]\n",
    "\n",
    "        #4. If only verb here \n",
    "        elif v_pos != -1 and adj_pos == -1 and adv_pos == -1:\n",
    "            target_pos = v_pos\n",
    "            target_word, pos = analyzed_sentence[target_pos]\n",
    "            mode = \"insert\"\n",
    "\n",
    "        #Else, return []\n",
    "        else:\n",
    "            return paraphrased_result\n",
    "            \n",
    "    \n",
    "        #find similar onomatopoeia    \n",
    "        similar_onomatope = self.find_similar_onomatope(target_word, top_n=5)\n",
    "   \n",
    "\n",
    "        #choose most similar one\n",
    "        if not similar_onomatope:\n",
    "            return paraphrased_result\n",
    "        \n",
    "        onoma, sim = similar_onomatope[0]\n",
    "\n",
    "        #if the similarity is too low, I would skip\n",
    "        if sim < 0.05:\n",
    "            return paraphrased_result\n",
    "\n",
    "        #find similar onomatope for the target(ind, word, pos)\n",
    "        #switch it to the onomatope\n",
    "        words = [w for w, _ in analyzed_sentence]\n",
    "\n",
    "        if mode == \"insert\":\n",
    "            words.insert(target_pos, onoma)\n",
    "        else:\n",
    "            words[target_pos] = onoma\n",
    "\n",
    "        new_sentence = \"\".join(words)\n",
    "        \n",
    "        #return the paraphrased sentence        \n",
    "        paraphrased_result.append({\n",
    "            'original sentence': sentence,\n",
    "            'paraphrased sentence': new_sentence,\n",
    "            'similarity': sim\n",
    "        })\n",
    "\n",
    "\n",
    "        return paraphrased_result\n",
    "    \n",
    "\n",
    "\n",
    "    #'prepare_and_train' method prepare for this whole model and train\n",
    "    #>>> This part does: set onomatope list, prepare training data, train word2vec\n",
    "    def prepare_and_train(self, training_sentences):\n",
    "        \n",
    "        random.seed(42)\n",
    "   \n",
    "\n",
    "        #Word2Vec training data\n",
    "        training_data = self.prepare_data_word2vec(training_sentences, max_sentences=500000)\n",
    "        \n",
    "        #train word2vec\n",
    "        self.train_word2vec(training_data)\n",
    "        \n",
    "        print(\"completed training model\")\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420e0d84-6d2f-43b2-8171-ad97a9590e59",
   "metadata": {},
   "source": [
    "__-How to implement the python code__\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbb6d8d4-f733-40e9-8e0c-84c2d2c6065c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 302 onomatopoeia from the list\n",
      "Loaded 89 additional onomatopoeia sentences\n",
      "loading corpus data\n",
      "loading corpus dataset, max=100000\n",
      "Loaded 100000 sentences\n",
      "preparing data for word2vec\n",
      "Completed preparation. The number of sentence for word2vec: 100089\n",
      "Training Word2Vec\n",
      "completed training word2vec model with 100089 sentences\n",
      "onomatope in word2vec vocab: 172, onomatope random vector added:130\n",
      "completed training model\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "please input a sentence that you want to paraphrase: 彼は歩く\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original sentence: 彼は歩く\n",
      "paraphrased sentence: 彼はこつこつ歩く\n",
      "similarity: 0.66275483\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    #https://www.tufs.ac.jp/common/fs/ilr/contents/ronshuu/26/jilr26_Article_Huang.pdf\n",
    "\n",
    "    #path to onomatope_list\n",
    "    onomatope_path = \"/Users/daikisuematsu/LING539/onomatopoeia-nlp/datasets/onomatope_list.txt\"\n",
    "    \n",
    "    #path to onomatope_sentences\n",
    "    additional_path = \"/Users/daikisuematsu/LING539/onomatopoeia-nlp/datasets/onomatope_sentences.txt\"\n",
    "\n",
    "    #prepare paraphraser\n",
    "    paraphraser = OnomatoParaphraser(onomatope_path, additional_path)\n",
    "\n",
    "    \n",
    "    #prepare corpus data for training\n",
    "    print(\"loading corpus data\")\n",
    "    training_sentences = paraphraser.load_dataset(max_sample=100000)\n",
    "\n",
    "    #prepare more training sentences of onomatopoeia for training\n",
    "    training_sentences.extend(paraphraser.additional_onoma_sentences)\n",
    "    \n",
    "    #prepare_and_train(self, onomatope_list, training_sentences):\n",
    "    paraphraser.prepare_and_train(training_sentences)\n",
    "\n",
    "    #input test_sentence\n",
    "    test_sentence = input(\"please input a sentence that you want to paraphrase:\")\n",
    "    results = paraphraser.paraphrase_sentence(test_sentence)\n",
    "       # paraphrased_result.append({\n",
    "        #            'original sentence': sentence,\n",
    "         #           'paraphrased sentence': new_sentence,\n",
    "          #          'similarity': sim\n",
    "           #     })\n",
    "    \n",
    "    if results:\n",
    "        for result in results:\n",
    "            print(\"original sentence:\", result['original sentence'])\n",
    "            print(\"paraphrased sentence:\", result['paraphrased sentence'])\n",
    "            print(\"similarity:\", result['similarity'])\n",
    "    else:\n",
    "        print(\"Failed to paraphrase\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50893d34-265b-47ff-81c1-09049f505148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 302 onomatopoeia from the list\n",
      "Loaded 89 additional onomatopoeia sentences\n",
      "loading corpus dataset, max=100000\n",
      "Loaded 100000 sentences\n",
      "preparing data for word2vec\n",
      "Completed preparation. The number of sentence for word2vec: 100089\n",
      "Training Word2Vec\n",
      "completed training word2vec model with 100089 sentences\n",
      "onomatope in word2vec vocab: 172, onomatope random vector added:130\n",
      "completed training model\n"
     ]
    }
   ],
   "source": [
    "#Prepare for testing the word2vec model\n",
    "onomatope_path = \"/Users/daikisuematsu/LING539/onomatopoeia-nlp/datasets/onomatope_list.txt\"\n",
    "additional_path = \"/Users/daikisuematsu/LING539/onomatopoeia-nlp/datasets/onomatope_sentences.txt\"\n",
    "\n",
    "paraphraser = OnomatoParaphraser(onomatope_path, additional_path)\n",
    "\n",
    "training_sentences = paraphraser.load_dataset(max_sample=100000)\n",
    "training_sentences.extend(paraphraser.additional_onoma_sentences)\n",
    "\n",
    "paraphraser.prepare_and_train(training_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "423a0299-b7bc-416e-8a17-45dd21d7ed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the word2vec model\n",
    "def test_similarity(paraphraser, top_n=5):\n",
    "\n",
    "    test_word = input(\"please input a word\").strip()\n",
    "\n",
    "    print(f\"Similar onomatopoeia of {test_word}  Top {top_n}：\")\n",
    "    similar = paraphraser.find_similar_onomatope(test_word, top_n=5)\n",
    "\n",
    "    if not similar:\n",
    "        print(\"no words in word2vec\")\n",
    "        return\n",
    "    \n",
    "    for onoma, sim in similar:\n",
    "        print(f\"{onoma}: {sim:.4f}\")\n",
    "        \n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a717c944-e5f2-4a64-b9a3-d7cb8a5aaed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "please input a word 食べる\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar onomatopoeia of 食べる  Top 5：\n",
      "からから: 0.7096\n",
      "ワイワイ: 0.7022\n",
      "さっと: 0.6892\n",
      "がっかり: 0.6867\n",
      "さっぱり: 0.6839\n"
     ]
    }
   ],
   "source": [
    "#test the model\n",
    "test_similarity(paraphraser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f2340e-db36-4abf-8b4a-c09b0aeefae2",
   "metadata": {},
   "source": [
    "# Result\n",
    "\n",
    "The model generated the following outputs. When the target word was either an adverb or an adjective, the model replaced it with an onomatopoeia. For verbs, the model inserted an onomatopoeia immediately before the verb.\n",
    "As a native Japanese speaker, I evaluated each suggested onomatopoeia for semantic appropriateness. In patterns 1 and 2 (involving adverbs and adjectives), I marked with an \"S\" those onomatopoeia that were somewhat semantically similar to the target word's meaning within a context. For pattern 3 (involving verbs), I marked with an \"S\" those cases where the onomatopoeia appropriately matched the verb. Cases that were semantically inappropriate were marked with an \"X\".\n",
    "\n",
    "The accuracy rates for each pattern were:\n",
    "\n",
    "- **Result1(Adverbs)**:8/30(26%)\n",
    "- **Result2(Adjectives)**: 7/30(23%)\n",
    "- **Result3(Verbs)**: 5/35(14%)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Pattern 1: Adverb to onomatopoeia\n",
    "Similar onomatopoeia of 遅く(slowly, lately)  Top 5：\n",
    "- ジメジメ: 0.6864 | x\n",
    "- ぐったり: 0.6815 | x\n",
    "- ぐっすり: 0.6734 | x\n",
    "- ぎりぎり: 0.6651 | S\n",
    "- メチャメチャ: 0.6647 | x\n",
    "\n",
    "Similar onomatopoeia of おそく(slowly, lately)  Top 5：\n",
    "- メチャメチャ: 0.8546 | x\n",
    "- ガックリ: 0.8528 | x\n",
    "- カンカン: 0.8342 | x\n",
    "- ぐしゃぐしゃ: 0.8319 | x\n",
    "- ごつごつ: 0.8303 | x\n",
    "\n",
    "Similar onomatopoeia of 早く(quickly)  Top 5：\n",
    "- イライラ: 0.6549 | x\n",
    "- ぐっすり: 0.6529 | x\n",
    "- がっかり: 0.6280 | x\n",
    "- ジメジメ: 0.6212 | x\n",
    "- モリモリ: 0.6148 | x\n",
    "\n",
    "Similar onomatopoeia of はやく(quickly)  Top 5：\n",
    "- コッテリ: 0.8709 | x\n",
    "- ザラザラ: 0.8703  | x\n",
    "- ギクシャク: 0.8602 | x\n",
    "- アッサリ: 0.8563 | S\n",
    "- ウロウロ: 0.8549 | x\n",
    "\n",
    "Similar onomatopoeia of 激しく(aggresively, intensely)  Top 5：\n",
    "- ぐんぐん: 0.7755 | x\n",
    "- グイグイ: 0.7667 | S\n",
    "- ジメジメ: 0.7504 | x\n",
    "- ぐっと: 0.7358 | S\n",
    "- イライラ: 0.7255 | x\n",
    "\n",
    "Similar onomatopoeia of はげしく(aggresively, intensely)  Top 5：\n",
    "'はげしく' is not in the vocabulary.\n",
    "no words in word2vec\n",
    "\n",
    "Similar onomatopoeia of 強く(strongly)  Top 5：\n",
    "- ぐんぐん: 0.7068 | S\n",
    "- モリモリ: 0.6954 | S\n",
    "- ぐっと: 0.6867 | x\n",
    "- くっきり: 0.6619 | S\n",
    "- グイグイ: 0.6534 | S\n",
    "\n",
    "Similar onomatopoeia of つよく(strongly)  Top 5：\n",
    "'つよく' is not in the vocabulary.\n",
    "no words in word2vec\n",
    "\n",
    "**Result1**:8/30(26%)\n",
    "\n",
    "## Pattern 2: Adjective to onomatopoeia\n",
    "Similar onomatopoeia of きれい(beautiful)  Top 5：\n",
    "- モリモリ: 0.6682 | x\n",
    "- クルクル: 0.6584 | x\n",
    "- くっきり: 0.6508 | S\n",
    "- キョロキョロ: 0.6408 | x\n",
    "- さっと: 0.6403 | x\n",
    "\n",
    "Similar onomatopoeia of やわらかい(soft)  Top 5：\n",
    "- しっとり: 0.8759 | x\n",
    "- こんがり: 0.8232 | x\n",
    "- ゴシゴシ: 0.8223 | x\n",
    "- ほんのり: 0.8070 | x\n",
    "- シャキシャキ: 0.8053 | x\n",
    "\n",
    "Similar onomatopoeia of 静か(quiet)  Top 5：\n",
    "- モリモリ: 0.6682 | x\n",
    "- ぐったり: 0.6607 | x\n",
    "- わいわい: 0.6499 | x\n",
    "- ぐいぐい: 0.6348 | x\n",
    "- おっとり: 0.6257 | S\n",
    "\n",
    "Similar onomatopoeia of しずか(quiet)  Top 5：\n",
    "'しずか' is not in the vocabulary.\n",
    "no words in word2vec\n",
    "\n",
    "Similar onomatopoeia of 楽しい(fun)  Top 5：\n",
    "- ワクワク: 0.7128 | S\n",
    "- ワイワイ: 0.6901 | S\n",
    "- めちゃめちゃ: 0.6825 | x\n",
    "- ぐっと: 0.6513 | x\n",
    "- ころころ: 0.6489 | x\n",
    "\n",
    "Similar onomatopoeia of たのしい(fun)  Top 5：\n",
    "- うだうだ: 0.7752 | x\n",
    "- わいわい: 0.7744 | S\n",
    "- シッカリ: 0.7653 | x\n",
    "- ポンポン: 0.7573 | x\n",
    "- もりもり: 0.7539 | x\n",
    "\n",
    "Similar onomatopoeia of にぎやか(lively)  Top 5：\n",
    "- げっそり: 0.8616 | x\n",
    "- ぐんぐん: 0.8461 | x\n",
    "- わいわい: 0.8436 | S\n",
    "- メチャメチャ: 0.8412 | x\n",
    "- ワイワイ: 0.8392 | S\n",
    "\n",
    "**Result2**: 7/30(23%)\n",
    "\n",
    "## Pattern 3: Add an onomatopoeia in front of the verb(dictionary form) \n",
    "\n",
    "Similar onomatopoeia of 歩く(to walk)  Top 5：\n",
    "- じっと: 0.6458 | x\n",
    "- こつこつ: 0.6444 | S\n",
    "- きらきら: 0.6287 | x\n",
    "- うろうろ: 0.6197 | S\n",
    "- げっそり: 0.6164 | x\n",
    "\n",
    "Similar onomatopoeia of あるく(to walk)  Top 5：\n",
    "- ザラザラ: 0.9031 | x\n",
    "- ガサガサ: 0.8997 | x\n",
    "- うんと: 0.8996 | x\n",
    "- ゴツゴツ: 0.8946 | x\n",
    "- ゴタゴタ: 0.8943 | x\n",
    "\n",
    "Similar onomatopoeia of 降る(to rain)  Top 5：\n",
    "- ジメジメ: 0.7663 | x\n",
    "- うんざり: 0.7361 | x\n",
    "- ぐったり: 0.7345 | x\n",
    "- じめじめ: 0.7303 | x\n",
    "- ころころ: 0.7191 | x\n",
    "\n",
    "Similar onomatopoeia of 揺れる(to quake)  Top 5：\n",
    "- ごろごろ: 0.8578 | x\n",
    "- ころころ: 0.8460 | x\n",
    "- くるくる: 0.8312 | x\n",
    "- くっきり: 0.8299 | x\n",
    "- ほんのり: 0.8298 | x\n",
    "\n",
    "Similar onomatopoeia of ゆれる(to quake)  Top 5：\n",
    "- げんなり: 0.8542 | x\n",
    "- グッタリ: 0.8527 | x\n",
    "- コッテリ: 0.8462 | x\n",
    "- がさがさ: 0.8450 | S\n",
    "- ぎくしゃく: 0.8398 | x\n",
    "\n",
    "Similar onomatopoeia of 笑う(to laugh)  Top 5：\n",
    "- げらげら: 0.8411 | S\n",
    "- ガンガン: 0.8390 | x\n",
    "- ワイワイ: 0.8382 | x\n",
    "- がっかり: 0.8365 | x\n",
    "- めちゃめちゃ: 0.8344 | S\n",
    "\n",
    "Similar onomatopoeia of 言う(to say)  Top 5：\n",
    "- ぼんやり: 0.6887 | x\n",
    "- じめじめ: 0.6785 | x\n",
    "- めちゃくちゃ: 0.6706 | x\n",
    "- モリモリ: 0.6680 | x\n",
    "- メチャクチャ: 0.6660 | x\n",
    "\n",
    "\n",
    "**Result3**: 5/35(14%)\n",
    "\n",
    "\n",
    "## Pattern 3.5: Add an onomatopoeia in front of the verb(present progressive form) \n",
    "\n",
    "Similar onomatopoeia of 歩いています(is walking)  Top 5：\n",
    "'歩いています' is not in the vocabulary.\n",
    "no words in word2vec\n",
    "\n",
    "Similar onomatopoeia of あるいています(is walking)  Top 5：\n",
    "'あるいています' is not in the vocabulary.\n",
    "no words in word2vec\n",
    "\n",
    "Similar onomatopoeia of 揺れている(is quaking)  Top 5：\n",
    "'揺れている' is not in the vocabulary.\n",
    "no words in word2vec\n",
    "\n",
    "Similar onomatopoeia of ゆれている(is quaking)  Top 5：\n",
    "'ゆれている' is not in the vocabulary.\n",
    "no words in word2vec\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813364a8-aa4f-4078-a327-ebcf7b7f95da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import jaconv\n",
    "\n",
    "katakana_text = \"\"\"アタフタ アッサリ アヤフヤ イソイソ イライラ ウキウキ ウジャウジャ \n",
    "        ウダウダ ウッカリ ウッスラ ウットリ ウツラウツラ ウトウト ウロウロ ウンザリ ウント オイオイ オズオズ\n",
    "        オソルオソル オットリ カサカサ ガサガサ カタカタ ガタガタ カチカチ ガチャガチャ ガツガツ \n",
    "        ガッカリ ガックリ ガッチリ カット ガミガミ カラカラ カラット ガラリト カリカリ\n",
    "        ガリガリ カンカン ガンガン ギクシャク ギザギザ ギスギス キチント ギッシリ キッチリ キット キッパリ キビキビ\n",
    "        ギュット ギョット キョロキョロ キラキラ ギラギラ ギリギリ グイグイ グウグウ クシャクシャ グシャグシャ クスクス クタクタ\n",
    "        グチャグチャ クッキリ グツグツ グッスリ グッタリ グット クヨクヨ グラグラ クリクリ クルクル グルグル クルリ\n",
    "        グングン グント ゲッソリ ゲラゲラ ケロット ゲンナリ ゴクゴク ゴシゴシ コソコソ ゴソゴソ ゴタゴタ ゴチャゴチャ\n",
    "        コツコツ ゴツゴツ コッソリ ゴッチャ コッテリ コトコト コロコロ ゴロゴロ ゴワゴワ コンガリ コンコン コンモリ\n",
    "        サクサク ザックバラン ザックリ サッサト サット ザット サッパリ サラサラ ザラザラ ザワザワ シクシク シゲシゲ\n",
    "        シッカリ シックリ ジックリ ジット シットリ シトシト シバシバ ジメジメ シャキシャキ シャックリ シャブシャブ ジャラジャラ\n",
    "        アタフタ アッサリ アヤフヤ イソイソ イライラ ウキウキ ウジャウジャ ウダウダ ウッカリ ウッスラ ウットリ ウツラウツラ\n",
    "        ウトウト ウロウロ ウンザリ ウント オイオイ オズオズ オソルオソル オットリ カサカサ ガサガサ カタカタ ガタガタ\n",
    "        カチカチ ガチャガチャ ガツガツ ガッカリ ガックリ ガッチリ カット ガミガミ カラカラ カラット ガラリト カリカリ\n",
    "        ガリガリ カンカン ガンガン ギクシャク ギザギザ ギスギス キチント ギッシリ キッチリ キット キッパリ キビキビ\n",
    "        ギュット ギョット キョロキョロ キラキラ ギラギラ ギリギリ グイグイ グウグウ クシャクシャ グシャグシャ クスクス クタクタ\n",
    "        グチャグチャ クッキリ グツグツ グッスリ グッタリ グット クヨクヨ グラグラ クリクリ クルクル グルグル クルリ\n",
    "        グングン グント ゲッソリ ゲラゲラ ケロット ゲンナリ ゴクゴク ゴシゴシ コソコソ ゴソゴソ ゴタゴタ ゴチャゴチャ\n",
    "        コツコツ ゴツゴツ コッソリ ゴッチャ コッテリ コトコト コロコロ ゴロゴロ ゴワゴワ コンガリ コンコン コンモリ\n",
    "        サクサク ザックバラン ザックリ サッサト サット ザット サッパリ サラサラ ザラザラ ザワザワ シクシク シゲシゲ\n",
    "        シッカリ シックリ ジックリ ジット シットリ シトシト シバシバ ジメジメ シャキシャキ シャックリ シャブシャブ ジャラジャラ\n",
    "        ホトホト ホノボノ ボヤボヤ ボロボロ ポロポロ ホンノリ ポンポン ボンヤリ マチマチ ムカムカ ムシャクシャ ムッツリ メチャ メチャクチャ\n",
    "        メチャメチャ モクモク モタモタ モリモリ モロモロ ヤキモキ ヤンワリ ユックリ ユッタリ ヨタヨタ ヨチヨチ ヨボヨボ\n",
    "        ヨレヨレ ヨロヨロ ワイワイ ワクワク ワンワン\"\"\"\n",
    "\n",
    "# 単語ごとに分割して変換\n",
    "words = katakana_text.split()\n",
    "hiragana_words = [jaconv.kata2hira(word) for word in words]\n",
    "\n",
    "# 結果表示\n",
    "hiragana_text = \" \".join(hiragana_words)\n",
    "print(hiragana_text)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "05befee1-c627-4e33-bde0-9dbb74b59032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"不合格の知らせにがっかりとさせられた\", \"仕事がうまくいかなくてがっかりだ\", \"生徒たちががやがやさわいでいる\",\n",
      "\"パーティ会場はがやがやしていた\", \"がやがやした店は好きじゃない\", \"のどがかわいて、からからだ\",\n",
      "\"洗濯物がからからに乾いた\", \"からから天気の日が続く\", \"がらがらとシャッターを開ける\",\n",
      "\"地震でへいががらがらと崩れた\", \"歌いすぎてのどががらがらになった\", \"家に帰ったらすぐ，がらがらとうがいをする\",\n",
      "\"店員ががらがら声で客を呼びこんでいる\", \"がんがん工事をする音が聞こえる\", \"野球のコーチががんがん怒鳴っている\",\n",
      "\"二日酔いで頭ががんがんする\", \"クーラーをがんがんにきかせる\", \"毎日朝ごはんをきちんと食べている\",\n",
      "\"本棚に本をきちんと並べる\", \"家賃を毎月きちんと払う\", \"財布にお札がぎっしりつまっている\",\n",
      "\"今週は予定がぎっしりだ\", \"小さな字でぎっしりと書いてある\", \"家具のサイズをきっちり測る\",\n",
      "\"本棚に本がきっちり入れてある\", \"借りたお金はきっちり返す\", \"セールスの電話はきっぱり断る\",\n",
      "\"今日からたばこはきっぱりやめる\", \"きっぱりとした態度をとる\", \"空の星がきらきら光る\",\n",
      "\"子供は目がきらきらしている\", \"パーティにきらきらの服を着ていく\", \"走っていったらぎりぎり間に合った\",\n",
      "\"合格点ぎりぎりでパスした\", \"ぎりぎりのお金しか持っていかない\", \"締め切りぎりぎりにならないと書き始めない\",\n",
      "\"マンガを読んでくすくすと笑っている\", \"くすくす笑いをしている\", \"ぐずぐずしていると間に合わない\",\n",
      "\"花粉症で鼻がぐずぐずする\", \"きのうの夜は、ぐっすり眠れた\", \"子供がぐっすりと寝ている\",\n",
      "\"最近どうもぐっすり寝られない\", \"重いドアをぐっと押す\", \"泣きたくてもぐっとがまんする\",\n",
      "\"冷たいビールをぐっと飲む\", \"コマがくるくる回る\", \"カレンダーをくるくる丸めた\",\n",
      "\"くるくるに巻いた髪\", \"道に迷ってぐるぐる歩き回った\", \"乗り物がぐるぐる回転する\",\n",
      "\"酔っ払って目がぐるぐる回る\", \"ロープでぐるぐる巻きにする\", \"病気でげっそりとやせた\",\n",
      "\"げっそりした表情で帰ってきた\", \"毎日同じものを食べてげっそりする\", \"漫画を読んでげらげら笑っている\",\n",
      "\"げらげら笑いすぎてお腹が痛くなった\", \"人の失敗をげらげらと笑うのは失礼だ\", \"引き出しの中がごちゃごちゃだ\",\n",
      "\"小さな店がごちゃごちゃと建っている\", \"ごちゃごちゃした模様は好きじゃない\", \"映画のストーリーがごちゃごちゃしてわかりにくい\",\n",
      "\"テーブルの上の料理をこっそり食べた\", \"夜遅くこっそりと家を出た\", \"ピンポン玉がころころところがる\",\n",
      "\"ころころと太った子犬\", \"言うことがころころ変わる\", \"試合にころころ負ける\",\n",
      "\"雷がごろごろなる\", \"猫がごろごろとのどを鳴らす\", \"お腹がごろごろする\",\n",
      "\"荷物がごろごろ転がる\", \"雨がざあざあ降っている\", \"外はざあざあ降りの大雨だ\",\n",
      "\"一人でさっさと帰ってしまった\", \"宿題をさっさと片付ける\", \"５時になったらさっと帰る\",\n",
      "\"テーブルの上をさっと片付ける\", \"雨がさっと降ってすぐやんだ\", \"資料にざっと目を通す\",\n",
      "\"バケツの水をざっとかける\", \"袋に入った米がざっとこぼれた\", \"ざっと計算して100万円はかかる\",\n",
      "\"長い髪をさっぱりと短くした\", \"デザートはさっぱり(と)した果物が食べたい\", \"難しくてさっぱりわからない\",\n",
      "\"髪がさらさらできれいだ\", \"さらさらの粉雪が降りつもっている\", \"さらさらっとサインする\",\n",
      "\"砂がさらさら(と)こぼれる\", \"砂がざらざらと落ちた\", \"風が強い日は，床がざらざらになる\",\n",
      "\"おばあちゃんの手はざらざらだ\", \"家の土台がしっかりしている\", \"子どもが母親にしっかりつかまっている\",\n",
      "\"若いときからしっかり貯金している\", \"しっかりした計画を立てる\", \"将来のことをじっくり考えて決める\",\n",
      "\"じっくり煮込んだシチューを作る\", \"痛くてもじっとがまんする\", \"心配でじっとしていられない\",\n",
      "\"人をじろじろ見るのは失礼だ\", \"店員にじろじろ見られた\", \"薬を飲んですっかり良くなった\",\n",
      "\"宿題のことをすっかり忘れていた\n",
      "もうすっかり一人前の大人だ\", \"部屋を片付けてすっきりした\", \"今朝は、すっきり起きられた\",\n",
      "\"すっきりしたデザインの洋服\", \"冷たいものを飲むとすっとする\", \"音もなくすっと部屋に入ってきた\",\n",
      "\"悪者がつかまって，胸がすっとした\", \"このペンはすらすら書ける\", \"難しい問題をすらすら解いた\",\n",
      "\"駐車場に観光バスがずらりと並んでいる\", \"世界各国のワインをずらりとそろえている\", \"重い荷物をずるずるとひきずる\",\n",
      "\"ずるずると返事をのばしている\", \"悪い仲間とずるずる付き合う\", \"親子で声がそっくりだ\",\n",
      "\"これとそっくりのかばんを持っている\", \"本物とそっくりに作ってある\", \"どろぼうが金庫の中身をそっくり盗んだ\",\n",
      "\"ワイングラスをそっと持つ\", \"うしろの出口からそっと帰る\", \"この問題には触れずにそっとしておこう\",\n",
      "\"もう遅いからそろそろ帰ろう\", \"息子もそろそろ結婚を考える歳になった\", \"足が痛いのでそろそろと歩いている\",\n",
      "\"観光客がぞろぞろ降りてきた\", \"なべにお湯をたっぷり入れる\", \"時間がたっぷりある\",\n",
      "\"たっぷりした服を着る\", \"だぶだぶのズボンが流行する\", \"お腹の肉がだぶだぶしている\",\n",
      "\"食事の前にちゃんと手を洗う\", \"小さな子供たちがちゃんと並んでいる\", \"床がつるつるしていて危ない\",\n",
      "\"つるつるの肌になる\", \"スピーチをするとき、どきどきした\", \"走ったあとは、心臓がどきどきする\",\n",
      "\"テストの点を見るときはいつもどきどきだ\", \"1日中歩き回ってどっと疲れた\", \"電車から人がどっと降りてくる\",\n",
      "\"ドアをどんどんとたたく音がする\", \"祭りの太鼓をどんどんたたく\", \"日本語がどんどん上手になる\",\n",
      "\"駅前にマンションがどんどん建つ\", \"ジャングルの中をどんどん進む\", \"赤ちゃんがにこにこ笑っている\",\n",
      "\"ちえ子さんはいつもにこにこしている\", \"ボーナスをもらってにこにこ顔だ\", \"携帯メールを見ながらにやにやしている\",\n",
      "\"授業中にやにや笑っていて先生に怒られた\", \"急ににやにやした顔になった\", \"プールの底がぬるぬるしている\",\n",
      "\"油がついて，手がぬるぬるすべる\", \"ぬるぬるした海草が気持ち悪い\", \"納豆のねばねばが口につく\",\n",
      "\"ねばねばした食べ物は体にいい\", \"行列がのろのろと進んだ\", \"のろのろしていると遅れるよ\",\n",
      "\"連休で高速道路はどこものろのろ運転だ\", \"温泉に入ってのんびりする\", \"休みの日は、のんびりと過ごしたい\",\n",
      "\"赤ちゃんが手足をばたばたさせる\", \"暑さで人がばたばた倒れる\", \"朝はみんなばたばたと出かけていく\",\n",
      "\"忙しくてばたばたしている\", \"寝不足で頭がはっきりしない\", \"はっきりしない天気が続く\",\n",
      "\"20年前の友人とばったり会った\", \"選手はゴールに入ったとたんばったり（と）倒れた\", \"悪い夢を見てはっと目がさめた\",\n",
      "\"急ブレーキの音がしてはっとした\", \"車内アナウンスにはっとして飛び降りた\", \"ぱっと見て決めた\",\n",
      "\"うわさがぱっと広まる\", \"ボーナスをぱっと使ってしまった\", \"売り上げがぱっとしない\",\n",
      "\"木の葉がはらはらと散る\", \"涙がはらはらと落ちた\", \"人がばらばらと飛び出してきた\",\n",
      "\"家族の食事の時間がばらばらだ\", \"ジグソーパズルをばらばらにする\", \"ばらばら死体が発見された\",\n",
      "\"くつをぴかぴかにみがく\", \"ダイアモンドの指輪がぴかぴか(と)光る\", \"急に大きな音がしてびっくりした\",\n",
      "\"あの人がどろぼうだったとは、びっくりだ\", \"おじいさんから、びっくり箱をもらった\", \"くつのサイズがぴったり合った\",\n",
      "\"子供が母親にぴったりくっついている\", \"体にぴったりした服を着る\", \"パンがふっくらと焼けた\",\n",
      "\"モデルにしてはふっくらした体型だ\", \"ふと後ろを見ると，先生が立っていた\", \"ふとしたことから知り合った\",\n",
      "\"忘れていた用事をふと思い出した\", \"寝不足でふらふらする\", \"酔っ払いがふらふら歩いている\",\n",
      "\"ビデオで撮った画面がふらふら揺れる\", \"悪い友達にふらふらとついていく\", \"ふらふらと遊び歩いている\",\n",
      "\"電気のひもがぶらぶら揺れる\", \"小さな子供が足をぶらぶらさせている\", \"街をぶらぶらと歩く\",\n",
      "\"こわくて足がぶるぶるする\", \"犬がぶるぶるっと体をふるわせた\", \"お腹がすいてぺこぺこだ\",\n",
      "\"電話をかけながら、ぺこぺこ頭を下げる\", \"社長の前ではぺこぺこする\", \"アルミの皿がぺこぺこする\",\n",
      "\"外国語がぺらぺらだ\", \"ぺらぺらよくしゃべる\", \"ページをぺらぺらとめくる\",\n",
      "\"ぺらぺらの紙\", \"頭がぼうっとしてきた\", \"ぼうっとテレビを見ていた\",\n",
      "\"試験に合格してほっとした\", \"手術が無事に終わってほっと安心した\", \"頂上に着いてほっと一息つく\",\n",
      "\"ぼろぼろの辞書を使っている\", \"試合でぼろぼろに負けた\", \"車がぼろぼろだ\",\n",
      "\"彼はぼんやりした人だ\", \"遠くの山がぼんやりと見える\", \"昔のことをぼんやりと覚えている\",\n",
      "\"船酔いで胸がむかむかする\", \"食べ過ぎて胃がむかむかする\", \"弟に負けてむかむかした\",\n",
      "\"Ｂ君の作文はめちゃくちゃだ\", \"地震で家がめちゃくちゃにこわれた\", \"あの店はめちゃくちゃな値段をつけている\",\n",
      "\"Ｔ大学に合格してめちゃくちゃうれしい\", \"男の子たちがもりもり食べている\", \"やる気がもりもりわいてきた\",\n",
      "\"ボディビルの選手は筋肉もりもりだ\", \"もっとゆっくり話してください\", \"川の水がゆっくり流れている\",\n",
      "\"みんなゆっくりしたペースで走っている\", \"おじいさんがよろよろ歩いている\", \"あっちへよろよろ，こっちへよろよろする\",\n",
      "\"ボクサーがよろよろと倒れる\", \"初めて海外旅行に行くのでわくわくする\", \"入学の日をわくわくしながら待っている\",\n",
      "\"『ハリー・ポッター』はわくわくどきどきの映画だ\", \"\",\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "text = \"\"\"\n",
    "不合格の知らせにがっかりとさせられた。仕事がうまくいかなくてがっかりだ。生徒たちががやがやさわいでいる。\n",
    "パーティ会場はがやがやしていた。がやがやした店は好きじゃない。のどがかわいて、からからだ。\n",
    "洗濯物がからからに乾いた。からから天気の日が続く。がらがらとシャッターを開ける。\n",
    "地震でへいががらがらと崩れた。歌いすぎてのどががらがらになった。家に帰ったらすぐ，がらがらとうがいをする。\n",
    "店員ががらがら声で客を呼びこんでいる。がんがん工事をする音が聞こえる。野球のコーチががんがん怒鳴っている。\n",
    "二日酔いで頭ががんがんする。クーラーをがんがんにきかせる。毎日朝ごはんをきちんと食べている。本棚に本をきちんと並べる。\n",
    "家賃を毎月きちんと払う。財布にお札がぎっしりつまっている。今週は予定がぎっしりだ。\n",
    "小さな字でぎっしりと書いてある。家具のサイズをきっちり測る。本棚に本がきっちり入れてある。\n",
    "借りたお金はきっちり返す。セールスの電話はきっぱり断る。今日からたばこはきっぱりやめる。\n",
    "きっぱりとした態度をとる。空の星がきらきら光る。子供は目がきらきらしている。\n",
    "パーティにきらきらの服を着ていく。走っていったらぎりぎり間に合った。\n",
    "合格点ぎりぎりでパスした。ぎりぎりのお金しか持っていかない。\n",
    "締め切りぎりぎりにならないと書き始めない。マンガを読んでくすくすと笑っている。\n",
    "くすくす笑いをしている。ぐずぐずしていると間に合わない。花粉症で鼻がぐずぐずする。きのうの夜は、ぐっすり眠れた。\n",
    "子供がぐっすりと寝ている。最近どうもぐっすり寝られない。重いドアをぐっと押す。\n",
    "泣きたくてもぐっとがまんする。冷たいビールをぐっと飲む。コマがくるくる回る。カレンダーをくるくる丸めた。\n",
    "くるくるに巻いた髪。道に迷ってぐるぐる歩き回った。\n",
    "乗り物がぐるぐる回転する。酔っ払って目がぐるぐる回る。\n",
    "ロープでぐるぐる巻きにする。病気でげっそりとやせた。\n",
    "げっそりした表情で帰ってきた。\n",
    "毎日同じものを食べてげっそりする。漫画を読んでげらげら笑っている。\n",
    "げらげら笑いすぎてお腹が痛くなった。\n",
    "人の失敗をげらげらと笑うのは失礼だ。引き出しの中がごちゃごちゃだ。\n",
    "小さな店がごちゃごちゃと建っている。\n",
    "ごちゃごちゃした模様は好きじゃない。\n",
    "映画のストーリーがごちゃごちゃしてわかりにくい。テーブルの上の料理をこっそり食べた。\n",
    "夜遅くこっそりと家を出た。ピンポン玉がころころところがる。ころころと太った子犬。\n",
    "言うことがころころ変わる。\n",
    "試合にころころ負ける。雷がごろごろなる。\n",
    "猫がごろごろとのどを鳴らす。\n",
    "お腹がごろごろする。\n",
    "荷物がごろごろ転がる。雨がざあざあ降っている。\n",
    "外はざあざあ降りの大雨だ。一人でさっさと帰ってしまった。\n",
    "宿題をさっさと片付ける。５時になったらさっと帰る。\n",
    "テーブルの上をさっと片付ける。\n",
    "雨がさっと降ってすぐやんだ。資料にざっと目を通す。\n",
    "バケツの水をざっとかける。\n",
    "袋に入った米がざっとこぼれた。\n",
    "ざっと計算して100万円はかかる。長い髪をさっぱりと短くした。\n",
    "デザートはさっぱり(と)した果物が食べたい。\n",
    "難しくてさっぱりわからない。髪がさらさらできれいだ。\n",
    "さらさらの粉雪が降りつもっている。\n",
    "さらさらっとサインする。\n",
    "砂がさらさら(と)こぼれる。砂がざらざらと落ちた。\n",
    "風が強い日は，床がざらざらになる。\n",
    "おばあちゃんの手はざらざらだ。家の土台がしっかりしている。\n",
    "子どもが母親にしっかりつかまっている。\n",
    "若いときからしっかり貯金している。\n",
    "しっかりした計画を立てる。将来のことをじっくり考えて決める。\n",
    "じっくり煮込んだシチューを作る。痛くてもじっとがまんする。\n",
    "心配でじっとしていられない。人をじろじろ見るのは失礼だ。\n",
    "店員にじろじろ見られた。薬を飲んですっかり良くなった。\n",
    "宿題のことをすっかり忘れていた\n",
    "もうすっかり一人前の大人だ。部屋を片付けてすっきりした。\n",
    "今朝は、すっきり起きられた。\n",
    "すっきりしたデザインの洋服。冷たいものを飲むとすっとする。\n",
    "音もなくすっと部屋に入ってきた。\n",
    "悪者がつかまって，胸がすっとした。このペンはすらすら書ける。\n",
    "難しい問題をすらすら解いた。駐車場に観光バスがずらりと並んでいる。\n",
    "世界各国のワインをずらりとそろえている。重い荷物をずるずるとひきずる。\n",
    "ずるずると返事をのばしている。\n",
    "悪い仲間とずるずる付き合う。親子で声がそっくりだ。\n",
    "これとそっくりのかばんを持っている。\n",
    "本物とそっくりに作ってある。\n",
    "どろぼうが金庫の中身をそっくり盗んだ。ワイングラスをそっと持つ。\n",
    "うしろの出口からそっと帰る。\n",
    "この問題には触れずにそっとしておこう。もう遅いからそろそろ帰ろう。\n",
    "息子もそろそろ結婚を考える歳になった。\n",
    "足が痛いのでそろそろと歩いている。観光客がぞろぞろ降りてきた。なべにお湯をたっぷり入れる。\n",
    "時間がたっぷりある。\n",
    "たっぷりした服を着る。だぶだぶのズボンが流行する。\n",
    "お腹の肉がだぶだぶしている。食事の前にちゃんと手を洗う。\n",
    "小さな子供たちがちゃんと並んでいる。床がつるつるしていて危ない。\n",
    "つるつるの肌になる。スピーチをするとき、どきどきした。\n",
    "走ったあとは、心臓がどきどきする。\n",
    "テストの点を見るときはいつもどきどきだ。1日中歩き回ってどっと疲れた。\n",
    "電車から人がどっと降りてくる。ドアをどんどんとたたく音がする。\n",
    "祭りの太鼓をどんどんたたく。\n",
    "日本語がどんどん上手になる。\n",
    "駅前にマンションがどんどん建つ。\n",
    "ジャングルの中をどんどん進む。赤ちゃんがにこにこ笑っている。\n",
    "ちえ子さんはいつもにこにこしている。\n",
    "ボーナスをもらってにこにこ顔だ。携帯メールを見ながらにやにやしている。\n",
    "授業中にやにや笑っていて先生に怒られた。\n",
    "急ににやにやした顔になった。プールの底がぬるぬるしている。\n",
    "油がついて，手がぬるぬるすべる。\n",
    "ぬるぬるした海草が気持ち悪い。納豆のねばねばが口につく。\n",
    "ねばねばした食べ物は体にいい。行列がのろのろと進んだ。\n",
    "のろのろしていると遅れるよ。\n",
    "連休で高速道路はどこものろのろ運転だ。温泉に入ってのんびりする。\n",
    "休みの日は、のんびりと過ごしたい。赤ちゃんが手足をばたばたさせる。\n",
    "暑さで人がばたばた倒れる。\n",
    "朝はみんなばたばたと出かけていく。\n",
    "忙しくてばたばたしている。寝不足で頭がはっきりしない。\n",
    "はっきりしない天気が続く。20年前の友人とばったり会った。\n",
    "選手はゴールに入ったとたんばったり（と）倒れた。悪い夢を見てはっと目がさめた。\n",
    "急ブレーキの音がしてはっとした。\n",
    "車内アナウンスにはっとして飛び降りた。ぱっと見て決めた。\n",
    "うわさがぱっと広まる。\n",
    "ボーナスをぱっと使ってしまった。\n",
    "売り上げがぱっとしない。木の葉がはらはらと散る。\n",
    "涙がはらはらと落ちた。人がばらばらと飛び出してきた。\n",
    "家族の食事の時間がばらばらだ。\n",
    "ジグソーパズルをばらばらにする。\n",
    "ばらばら死体が発見された。くつをぴかぴかにみがく。\n",
    "ダイアモンドの指輪がぴかぴか(と)光る。急に大きな音がしてびっくりした。\n",
    "あの人がどろぼうだったとは、びっくりだ。\n",
    "おじいさんから、びっくり箱をもらった。くつのサイズがぴったり合った。\n",
    "子供が母親にぴったりくっついている。\n",
    "体にぴったりした服を着る。パンがふっくらと焼けた。モデルにしてはふっくらした体型だ。ふと後ろを見ると，先生が立っていた。\n",
    "ふとしたことから知り合った。\n",
    "忘れていた用事をふと思い出した。寝不足でふらふらする。\n",
    "酔っ払いがふらふら歩いている。\n",
    "ビデオで撮った画面がふらふら揺れる。\n",
    "悪い友達にふらふらとついていく。\n",
    "ふらふらと遊び歩いている。電気のひもがぶらぶら揺れる。\n",
    "小さな子供が足をぶらぶらさせている。\n",
    "街をぶらぶらと歩く。こわくて足がぶるぶるする。犬がぶるぶるっと体をふるわせた。お腹がすいてぺこぺこだ。\n",
    "電話をかけながら、ぺこぺこ頭を下げる。\n",
    "社長の前ではぺこぺこする。\n",
    "アルミの皿がぺこぺこする。外国語がぺらぺらだ。\n",
    "ぺらぺらよくしゃべる。ページをぺらぺらとめくる。\n",
    "ぺらぺらの紙。頭がぼうっとしてきた。\n",
    "ぼうっとテレビを見ていた。試験に合格してほっとした。\n",
    "手術が無事に終わってほっと安心した。\n",
    "頂上に着いてほっと一息つく。ぼろぼろの辞書を使っている。\n",
    "試合でぼろぼろに負けた。車がぼろぼろだ。彼はぼんやりした人だ。\n",
    "遠くの山がぼんやりと見える。\n",
    "昔のことをぼんやりと覚えている。船酔いで胸がむかむかする。\n",
    "食べ過ぎて胃がむかむかする。\n",
    "弟に負けてむかむかした。Ｂ君の作文はめちゃくちゃだ。\n",
    "地震で家がめちゃくちゃにこわれた。\n",
    "あの店はめちゃくちゃな値段をつけている。\n",
    "Ｔ大学に合格してめちゃくちゃうれしい。男の子たちがもりもり食べている。\n",
    "やる気がもりもりわいてきた。\n",
    "ボディビルの選手は筋肉もりもりだ。\n",
    "もっとゆっくり話してください。\n",
    "川の水がゆっくり流れている。\n",
    "みんなゆっくりしたペースで走っている。おじいさんがよろよろ歩いている。\n",
    "あっちへよろよろ，こっちへよろよろする。\n",
    "ボクサーがよろよろと倒れる。初めて海外旅行に行くのでわくわくする。\n",
    "入学の日をわくわくしながら待っている。\n",
    "『ハリー・ポッター』はわくわくどきどきの映画だ。\n",
    "\"\"\"\n",
    "\n",
    "lines = text.strip().split(\"。\")\n",
    "quoted_lines = ['\"' + line.strip() + '\",' for line in lines]\n",
    "\n",
    "for i in range(0, len(quoted_lines), 3):\n",
    "    row = quoted_lines[i: i+3]\n",
    "    print(\" \". join(row))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97cb09f-0532-45e6-a30e-34fdfef94947",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[\n",
    "        \"日本料理は味があっさりしている。\", \"こってりした味。\", \"あっさりしたデザインが好きだ。\", \"すっきりしたデザインの服。\", \"兄はあっさりした性格だ。\", \"チャンピオンがあっさりと負けた。\",\n",
    "        \"長い時間待たされていらいらする。\", \"隣の部屋がうるさくていらいらする。\", \"ドライバーのいらいらがつのる。\",\n",
    "        \"試験の点が悪いのは、うっかりミスが多いからだ。\",\"大切な約束をうっかり忘れてしまった。\",\"うっかりして降りる駅を乗り過ごした。\",\n",
    "        \"家の前をうろうろしている人がいる。\",\"クマがうろうろと動き回る。\",\"あっちへうろうろ、こっちへうろうろした。\",\n",
    "        \"宿題が多くてうんざりする。\",\"店長の小言にはもううんざりだ。\",\"乗客はうんざりした顔をしている。\",\n",
    "        \"地震がきて、戸ががたがた揺れた。\",\"古い机なのでがたがたする。\",\"寒くてがたがた震える。\",\n",
    "        \"料理がまずくてがっかりした。\", \"不合格の知らせにがっかりとさせられた\", \"仕事がうまくいかなくてがっかりだ\", \"生徒たちががやがやさわいでいる\",\n",
    "        \"パーティ会場はがやがやしていた\", \"がやがやした店は好きじゃない\", \"のどがかわいて、からからだ\",\n",
    "        \"洗濯物がからからに乾いた\", \"からから天気の日が続く\", \"がらがらとシャッターを開ける\",\n",
    "        \"地震でへいががらがらと崩れた\", \"歌いすぎてのどががらがらになった\", \"家に帰ったらすぐ，がらがらとうがいをする\",\n",
    "        \"店員ががらがら声で客を呼びこんでいる\", \"がんがん工事をする音が聞こえる\", \"野球のコーチががんがん怒鳴っている\",\n",
    "        \"二日酔いで頭ががんがんする\", \"クーラーをがんがんにきかせる\", \"毎日朝ごはんをきちんと食べている\",\n",
    "        \"本棚に本をきちんと並べる\", \"家賃を毎月きちんと払う\", \"財布にお札がぎっしりつまっている\",\n",
    "        \"今週は予定がぎっしりだ\", \"小さな字でぎっしりと書いてある\", \"家具のサイズをきっちり測る\",\n",
    "        \"本棚に本がきっちり入れてある\", \"借りたお金はきっちり返す\", \"セールスの電話はきっぱり断る\",\n",
    "        \"今日からたばこはきっぱりやめる\", \"きっぱりとした態度をとる\", \"空の星がきらきら光る\",\n",
    "        \"子供は目がきらきらしている\", \"パーティにきらきらの服を着ていく\", \"走っていったらぎりぎり間に合った\",\n",
    "        \"合格点ぎりぎりでパスした\", \"ぎりぎりのお金しか持っていかない\", \"締め切りぎりぎりにならないと書き始めない\",\n",
    "        \"マンガを読んでくすくすと笑っている\", \"くすくす笑いをしている\", \"ぐずぐずしていると間に合わない\",\n",
    "        \"花粉症で鼻がぐずぐずする\", \"きのうの夜は、ぐっすり眠れた\", \"子供がぐっすりと寝ている\",\n",
    "        \"最近どうもぐっすり寝られない\", \"重いドアをぐっと押す\", \"泣きたくてもぐっとがまんする\",\n",
    "        \"冷たいビールをぐっと飲む\", \"コマがくるくる回る\", \"カレンダーをくるくる丸めた\",\n",
    "        \"くるくるに巻いた髪\", \"道に迷ってぐるぐる歩き回った\", \"乗り物がぐるぐる回転する\",\n",
    "        \"酔っ払って目がぐるぐる回る\", \"ロープでぐるぐる巻きにする\", \"病気でげっそりとやせた\",\n",
    "        \"げっそりした表情で帰ってきた\", \"毎日同じものを食べてげっそりする\", \"漫画を読んでげらげら笑っている\",\n",
    "        \"げらげら笑いすぎてお腹が痛くなった\", \"人の失敗をげらげらと笑うのは失礼だ\", \"引き出しの中がごちゃごちゃだ\",\n",
    "        \"小さな店がごちゃごちゃと建っている\", \"ごちゃごちゃした模様は好きじゃない\", \"映画のストーリーがごちゃごちゃしてわかりにくい\",\n",
    "        \"テーブルの上の料理をこっそり食べた\", \"夜遅くこっそりと家を出た\", \"ピンポン玉がころころところがる\",\n",
    "        \"ころころと太った子犬\", \"言うことがころころ変わる\", \"試合にころころ負ける\",\n",
    "        \"雷がごろごろなる\", \"猫がごろごろとのどを鳴らす\", \"お腹がごろごろする\",\n",
    "        \"荷物がごろごろ転がる\", \"雨がざあざあ降っている\", \"外はざあざあ降りの大雨だ\",\n",
    "        \"一人でさっさと帰ってしまった\", \"宿題をさっさと片付ける\", \"５時になったらさっと帰る\",\n",
    "        \"テーブルの上をさっと片付ける\", \"雨がさっと降ってすぐやんだ\", \"資料にざっと目を通す\",\n",
    "        \"バケツの水をざっとかける\", \"袋に入った米がざっとこぼれた\", \"ざっと計算して100万円はかかる\",\n",
    "        \"長い髪をさっぱりと短くした\", \"デザートはさっぱり(と)した果物が食べたい\", \"難しくてさっぱりわからない\",\n",
    "        \"髪がさらさらできれいだ\", \"さらさらの粉雪が降りつもっている\", \"さらさらっとサインする\",\n",
    "        \"砂がさらさら(と)こぼれる\", \"砂がざらざらと落ちた\", \"風が強い日は，床がざらざらになる\",\n",
    "        \"おばあちゃんの手はざらざらだ\", \"家の土台がしっかりしている\", \"子どもが母親にしっかりつかまっている\",\n",
    "        \"若いときからしっかり貯金している\", \"しっかりした計画を立てる\", \"将来のことをじっくり考えて決める\",\n",
    "        \"じっくり煮込んだシチューを作る\", \"痛くてもじっとがまんする\", \"心配でじっとしていられない\",\n",
    "        \"人をじろじろ見るのは失礼だ\", \"店員にじろじろ見られた\", \"薬を飲んですっかり良くなった\",\n",
    "        \"宿題のことをすっかり忘れていた\", \"もうすっかり一人前の大人だ\", \"部屋を片付けてすっきりした\", \"今朝は、すっきり起きられた\",\n",
    "        \"すっきりしたデザインの洋服\", \"冷たいものを飲むとすっとする\", \"音もなくすっと部屋に入ってきた\",\n",
    "        \"悪者がつかまって，胸がすっとした\", \"このペンはすらすら書ける\", \"難しい問題をすらすら解いた\",\n",
    "        \"駐車場に観光バスがずらりと並んでいる\", \"世界各国のワインをずらりとそろえている\", \"重い荷物をずるずるとひきずる\",\n",
    "        \"ずるずると返事をのばしている\", \"悪い仲間とずるずる付き合う\", \"親子で声がそっくりだ\",\n",
    "        \"これとそっくりのかばんを持っている\", \"本物とそっくりに作ってある\", \"どろぼうが金庫の中身をそっくり盗んだ\",\n",
    "        \"ワイングラスをそっと持つ\", \"うしろの出口からそっと帰る\", \"この問題には触れずにそっとしておこう\",\n",
    "        \"もう遅いからそろそろ帰ろう\", \"息子もそろそろ結婚を考える歳になった\", \"足が痛いのでそろそろと歩いている\",\n",
    "        \"観光客がぞろぞろ降りてきた\", \"なべにお湯をたっぷり入れる\", \"時間がたっぷりある\",\n",
    "        \"たっぷりした服を着る\", \"だぶだぶのズボンが流行する\", \"お腹の肉がだぶだぶしている\",\n",
    "        \"食事の前にちゃんと手を洗う\", \"小さな子供たちがちゃんと並んでいる\", \"床がつるつるしていて危ない\",\n",
    "        \"つるつるの肌になる\", \"スピーチをするとき、どきどきした\", \"走ったあとは、心臓がどきどきする\",\n",
    "        \"テストの点を見るときはいつもどきどきだ\", \"1日中歩き回ってどっと疲れた\", \"電車から人がどっと降りてくる\",\n",
    "        \"ドアをどんどんとたたく音がする\", \"祭りの太鼓をどんどんたたく\", \"日本語がどんどん上手になる\",\n",
    "        \"駅前にマンションがどんどん建つ\", \"ジャングルの中をどんどん進む\", \"赤ちゃんがにこにこ笑っている\",\n",
    "        \"ちえ子さんはいつもにこにこしている\", \"ボーナスをもらってにこにこ顔だ\", \"携帯メールを見ながらにやにやしている\",\n",
    "        \"授業中にやにや笑っていて先生に怒られた\", \"急ににやにやした顔になった\", \"プールの底がぬるぬるしている\",\n",
    "        \"油がついて，手がぬるぬるすべる\", \"ぬるぬるした海草が気持ち悪い\", \"納豆のねばねばが口につく\",\n",
    "        \"ねばねばした食べ物は体にいい\", \"行列がのろのろと進んだ\", \"のろのろしていると遅れるよ\",\n",
    "        \"連休で高速道路はどこものろのろ運転だ\", \"温泉に入ってのんびりする\", \"休みの日は、のんびりと過ごしたい\",\n",
    "        \"赤ちゃんが手足をばたばたさせる\", \"暑さで人がばたばた倒れる\", \"朝はみんなばたばたと出かけていく\",\n",
    "        \"忙しくてばたばたしている\", \"寝不足で頭がはっきりしない\", \"はっきりしない天気が続く\",\n",
    "        \"20年前の友人とばったり会った\", \"選手はゴールに入ったとたんばったり（と）倒れた\", \"悪い夢を見てはっと目がさめた\",\n",
    "        \"急ブレーキの音がしてはっとした\", \"車内アナウンスにはっとして飛び降りた\", \"ぱっと見て決めた\",\n",
    "        \"うわさがぱっと広まる\", \"ボーナスをぱっと使ってしまった\", \"売り上げがぱっとしない\",\n",
    "        \"木の葉がはらはらと散る\", \"涙がはらはらと落ちた\", \"人がばらばらと飛び出してきた\",\n",
    "        \"家族の食事の時間がばらばらだ\", \"ジグソーパズルをばらばらにする\", \"ばらばら死体が発見された\",\n",
    "        \"くつをぴかぴかにみがく\", \"ダイアモンドの指輪がぴかぴか(と)光る\", \"急に大きな音がしてびっくりした\",\n",
    "        \"あの人がどろぼうだったとは、びっくりだ\", \"おじいさんから、びっくり箱をもらった\", \"くつのサイズがぴったり合った\",\n",
    "        \"子供が母親にぴったりくっついている\", \"体にぴったりした服を着る\", \"パンがふっくらと焼けた\",\n",
    "        \"モデルにしてはふっくらした体型だ\", \"ふと後ろを見ると，先生が立っていた\", \"ふとしたことから知り合った\",\n",
    "        \"忘れていた用事をふと思い出した\", \"寝不足でふらふらする\", \"酔っ払いがふらふら歩いている\",\n",
    "        \"ビデオで撮った画面がふらふら揺れる\", \"悪い友達にふらふらとついていく\", \"ふらふらと遊び歩いている\",\n",
    "        \"電気のひもがぶらぶら揺れる\", \"小さな子供が足をぶらぶらさせている\", \"街をぶらぶらと歩く\",\n",
    "        \"こわくて足がぶるぶるする\", \"犬がぶるぶるっと体をふるわせた\", \"お腹がすいてぺこぺこだ\",\n",
    "        \"電話をかけながら、ぺこぺこ頭を下げる\", \"社長の前ではぺこぺこする\", \"アルミの皿がぺこぺこする\",\n",
    "        \"外国語がぺらぺらだ\", \"ぺらぺらよくしゃべる\", \"ページをぺらぺらとめくる\",\n",
    "        \"ぺらぺらの紙\", \"頭がぼうっとしてきた\", \"ぼうっとテレビを見ていた\",\n",
    "        \"試験に合格してほっとした\", \"手術が無事に終わってほっと安心した\", \"頂上に着いてほっと一息つく\",\n",
    "        \"ぼろぼろの辞書を使っている\", \"試合でぼろぼろに負けた\", \"車がぼろぼろだ\",\n",
    "        \"彼はぼんやりした人だ\", \"遠くの山がぼんやりと見える\", \"昔のことをぼんやりと覚えている\",\n",
    "        \"船酔いで胸がむかむかする\", \"食べ過ぎて胃がむかむかする\", \"弟に負けてむかむかした\",\n",
    "        \"Ｂ君の作文はめちゃくちゃだ\", \"地震で家がめちゃくちゃにこわれた\", \"あの店はめちゃくちゃな値段をつけている\",\n",
    "        \"Ｔ大学に合格してめちゃくちゃうれしい\", \"男の子たちがもりもり食べている\", \"やる気がもりもりわいてきた\",\n",
    "        \"ボディビルの選手は筋肉もりもりだ\", \"もっとゆっくり話してください\", \"川の水がゆっくり流れている\",\n",
    "        \"みんなゆっくりしたペースで走っている\", \"おじいさんがよろよろ歩いている\", \"あっちへよろよろ，こっちへよろよろする\",\n",
    "        \"ボクサーがよろよろと倒れる\", \"初めて海外旅行に行くのでわくわくする\", \"入学の日をわくわくしながら待っている\",\n",
    "        \"『ハリー・ポッター』はわくわくどきどきの映画だ\", \n",
    "        ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(onomato-env)",
   "language": "python",
   "name": "onomato-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
