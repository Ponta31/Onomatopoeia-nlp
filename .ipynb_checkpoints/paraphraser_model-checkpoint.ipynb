{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79f9a54b-c6e2-4089-b850-4fe2f5ce4fc2",
   "metadata": {},
   "source": [
    "<h1>word2vec model and paraphrasing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d6bcb7-a17a-4bb2-a7d6-549cfbd12b01",
   "metadata": {},
   "source": [
    "**Dataset**\n",
    "\n",
    "A. Corpus for Japanese including onomatopoeia\n",
    "- https://huggingface.co/datasets/oscar-corpus/OSCAR-2201\n",
    "\n",
    "B. Article for onomatopoeia list\n",
    "- https://www.tufs.ac.jp/common/fs/ilr/contents/ronshuu/26/jilr26_Article_Huang.pdf\n",
    "\n",
    "C. Onomatopoeia website\n",
    "- https://www2.ninjal.ac.jp/Onomatope/50_on/gatagata.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5c0a4c9c-6a34-45e6-9097-0a5da1b8f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download libraries\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from gensim.models import Word2Vec\n",
    "import MeCab\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e0243f3b-c3e3-456d-8779-3d64a0e20341",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#OnomatoParaphraser\n",
    "\n",
    "class OnomatoParaphraser:\n",
    "    #initialize \n",
    "    #The tools I would need are \"tokens and POS\" to look into the original sentence \n",
    "    #                           \"onomatope list\" that I found in an article\n",
    "    #                           \"Word2Vec model\" \n",
    "    def __init__(self, onomatope_path, additional_path):\n",
    "        self.mecab = MeCab.Tagger(\"--rcfile=/opt/homebrew/etc/mecabrc\") \n",
    "        self.word2vec_model = None\n",
    "\n",
    "        with open(onomatope_path, 'r', encoding='utf-8') as f:\n",
    "            onomatope_lines = f.readlines()\n",
    "            \n",
    "        self.onomatope_list = []\n",
    "        for line in onomatope_lines:\n",
    "            onomatopes = line.strip().split()\n",
    "            self.onomatope_list.extend(onomatopes)\n",
    "\n",
    "        self.onomatope_list = list(set(self.onomatope_list))\n",
    "        print(f\"Loaded {len(self.onomatope_list)} onomatopoeia from the list\")\n",
    "                \n",
    "        with open(additional_path, 'r', encoding='utf-8') as f:\n",
    "            additional_onoma_sentences = f.readlines()\n",
    "\n",
    "        self.additional_onoma_sentences = [line.strip().strip(',') for line in additional_onoma_sentences if line.strip()]\n",
    "        print(f\"Loaded {len(self.additional_onoma_sentences)} additional onomatopoeia sentences\")\n",
    "\n",
    "    \n",
    "    #Mecab output format\n",
    "    #表層形\\t品詞,品詞細分類1,品詞細分類2,品詞細分類3,活用型,活用形,原形,読み,発音\n",
    "\n",
    "\n",
    "    \n",
    "    #Function to tokenize Japanese text with MeCab\n",
    "    def tokenize_text(self, text):\n",
    "        parsed_text = self.mecab.parse(text)\n",
    "        lines = parsed_text.split('\\n')\n",
    "        tokens = []\n",
    "\n",
    "        for line in lines:\n",
    "            if line == 'EOS' or line == '':\n",
    "                continue\n",
    "            parts = line.split('\\t')\n",
    "            if len(parts) >= 2:\n",
    "                tokens.append(parts[0])\n",
    "\n",
    "        return tokens\n",
    "\n",
    "    \n",
    "\n",
    "    #Analyze POS because depending on POS, onomatope gets different suffix\n",
    "    def analyze_sentence(self, sentence):\n",
    "        mecab_result = self.mecab.parse(sentence)\n",
    "        lines = mecab_result.split('\\n')\n",
    "\n",
    "        words = []\n",
    "        POS_tags = []\n",
    "        \n",
    "        for line in lines:\n",
    "            if line == 'EOS' or line == '':\n",
    "                continue\n",
    "            parts = line.split('\\t')\n",
    "            if len(parts) >= 2:\n",
    "                word = parts[0]\n",
    "                pos = parts[1].split(',')[0] #mecab.parse includes several information, and the first one is POS\n",
    "\n",
    "                words.append(word)\n",
    "                POS_tags.append(pos)\n",
    "        \n",
    "\n",
    "        return list(zip(words, POS_tags))\n",
    "        \n",
    "\n",
    " #load Japanese texts from the corpus\n",
    "    def load_dataset(self, max_sample):\n",
    "\n",
    "        print(f\"loading corpus dataset, max={max_sample}\")\n",
    "\n",
    "        dataset = load_dataset(\"oscar-corpus/OSCAR-2301\",\n",
    "                               language=\"ja\",\n",
    "                               streaming=True,\n",
    "                               split=\"train\",\n",
    "                              )\n",
    "        \n",
    "        \n",
    "        #RegEx to remove some symbols\n",
    "        symbol_pattern = re.compile(r'[■□※●○\\{\\}【】\\*]+')\n",
    "        \n",
    "        #save Japanese sentences\n",
    "        JP_sentences = []\n",
    "        count = 0\n",
    "\n",
    "        for sample in dataset:\n",
    "\n",
    "            #The corpus is Dict[\"id\":___, \"text\":___]\n",
    "            text = sample[\"text\"] \n",
    "\n",
    "            #I want to split with \\n and '。'\n",
    "            lines = text.split('\\n')\n",
    "            \n",
    "            for line in lines:\n",
    "                sentences = line.split('。')\n",
    "\n",
    "            #if the sentence has a symbol, I will not use it. Go to next sentence\n",
    "            for sentence in sentences:\n",
    "                if symbol_pattern.search(sentence):\n",
    "                    continue\n",
    "                \n",
    "            #if the sentence is too short or too long, should be removed\n",
    "                if 10 <= len(sentence) <= 140 and sentence.strip():\n",
    "                    JP_sentences.append(sentence)\n",
    "                    count += 1\n",
    "\n",
    "                    if count >= max_sample:\n",
    "                        print(f\"Loaded {len(JP_sentences)} sentences\")\n",
    "                        return JP_sentences\n",
    "\n",
    " \n",
    "        print(f\"Loaded {len(JP_sentences)} sentences from corpus\")\n",
    "        return JP_sentences\n",
    "\n",
    "        \n",
    "                    \n",
    "\n",
    "\n",
    "    \n",
    "    #tokenize sentences as preparation for the word2vec model\n",
    "    def prepare_data_word2vec(self, training_sentences, max_sentences):\n",
    "        print(\"preparing data for word2vec\")\n",
    "\n",
    "        #I want to make tokenized_sentences list and count the number of sentence\n",
    "        tokenized_sentences = []\n",
    "        count = 0\n",
    "\n",
    "        #if the number of sentence is over, should be break\n",
    "        for sentence in training_sentences:\n",
    "            if count >= max_sentences:\n",
    "                break\n",
    "\n",
    "            #tokenize text and add to tokenized_sentences list\n",
    "            tokens = self.tokenize_text(sentence)\n",
    "            tokenized_sentences.append(tokens)\n",
    "            count += 1\n",
    "\n",
    "        print(f\"Completed preparation. The number of sentence for word2vec: {count}\")\n",
    "        return tokenized_sentences\n",
    "        \n",
    "    \n",
    "    #train word2vec\n",
    "    def train_word2vec(self, tokenized_sentences):\n",
    "        print(\"Training Word2Vec\")\n",
    "\n",
    "        self.word2vec_model = Word2Vec(\n",
    "            sentences=tokenized_sentences,\n",
    "            vector_size=100,\n",
    "            window=5,\n",
    "            min_count=1,\n",
    "            sg=1, #skip_gram\n",
    "            epochs=10\n",
    "        )\n",
    "\n",
    "        print(f\"completed training word2vec model with {len(tokenized_sentences)} sentences\")\n",
    "       \n",
    "        #if the onomatope in my list is not in the word2vec model, \n",
    "        #adding random vector to the model for the onomatope\n",
    "        \n",
    "        onoma_in_vocab = 0\n",
    "        onoma_added = 0\n",
    "\n",
    "        new_vectors = []\n",
    "        new_words = []\n",
    "        \n",
    "        for onomatope in self.onomatope_list:\n",
    "            if onomatope in self.word2vec_model.wv:\n",
    "                onoma_in_vocab +=1\n",
    "            else:\n",
    "                random_vector = np.random.uniform(-0.25, 0.25, size=self.word2vec_model.vector_size)\n",
    "                new_words.append(onomatope)\n",
    "                new_vectors.append(random_vector)\n",
    "                onoma_added += 1\n",
    "\n",
    "        if new_words:\n",
    "            self.word2vec_model.wv.add_vectors(new_words, new_vectors)\n",
    "        \n",
    "        print(f\"onomatope in word2vec vocab: {onoma_in_vocab}, onomatope random vector added:{onoma_added}\")\n",
    "\n",
    "        return self.word2vec_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #using the vectors from word2Vec, find similar onomatopoeias for the word\n",
    "    def find_similar_onomatope(self, word, top_n=5):\n",
    "\n",
    "        if word not in self.word2vec_model.wv:\n",
    "            print(f\"'{word}' is not in the vocabulary.\")\n",
    "            return []\n",
    "        \n",
    "        #extract similarity of word from sentence and onomatope from onomatope list in word2vec\n",
    "        similarities = []\n",
    "        for onoma in self.onomatope_list:\n",
    "            if onoma in self.word2vec_model.wv:\n",
    "                sim = self.word2vec_model.wv.similarity(word, onoma)\n",
    "                similarities.append((onoma, sim))\n",
    "\n",
    "                \n",
    "        #sort from high score\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        return similarities[:top_n]\n",
    "\n",
    "\n",
    "    #paraphrase the sentence\n",
    "    def paraphrase_sentence(self, sentence):\n",
    "        #analyze the sentence\n",
    "        analyzed_sentence = self.analyze_sentence(sentence)\n",
    "\n",
    "        #paraphrased result [original sentence;__, new sentence:__, similarity:__]\n",
    "        paraphrased_result = []\n",
    "\n",
    "        #Conditions\n",
    "        #1. If the sentence contains all '副詞', '形容詞', and '動詞' in this order, paraphrase the  '形容詞'.\n",
    "        #2. If the sentence contains '副詞' and '動詞' in this order, paraphrase the  '動詞'.\n",
    "        #3. If the sentence contains '形容詞' without '動詞', paraphrase the '形容詞'.\n",
    "\n",
    "        #The method has not yet found the POS\n",
    "        adv_pos = -1\n",
    "        adj_pos = -1\n",
    "        v_pos = -1\n",
    "\n",
    "        #find the index of the POS\n",
    "        for i, (word, pos) in enumerate(analyzed_sentence):\n",
    "            if pos == '副詞':\n",
    "                if adv_pos == -1:\n",
    "                    adv_pos = i\n",
    "            elif pos == '形容詞':\n",
    "                if adj_pos == -1:\n",
    "                    adj_pos = i\n",
    "            elif pos == '動詞':\n",
    "                if v_pos == -1:\n",
    "                    v_pos = i\n",
    "\n",
    "        #1. If the sentence contains all '副詞', '形容詞', and '動詞' in this order, paraphrase the  '形容詞'.\n",
    "        if (\n",
    "            adv_pos != -1 and\n",
    "            adj_pos != -1 and\n",
    "            v_pos != -1 and\n",
    "            adv_pos +1 == adj_pos and\n",
    "            adj_pos +1 == v_pos\n",
    "        ):\n",
    "            target_pos = adj_pos\n",
    "            target_word, pos = analyzed_sentence[target_pos]\n",
    "\n",
    "        #2. If the sentence contains '副詞' and '動詞' in this order, paraphrase the  '動詞'.\n",
    "        elif adv_pos != -1 and v_pos != -1 and adv_pos +1 == v_pos:\n",
    "            target_pos = v_pos\n",
    "            target_word, pos = analyzed_sentence[target_pos]\n",
    "\n",
    "        #3. If the sentence contains '形容詞' without '動詞', paraphrase the '形容詞'.\n",
    "        elif adj_pos != -1 and v_pos == -1:\n",
    "            target_pos = adj_pos\n",
    "            target_word, pos = analyzed_sentence[target_pos]\n",
    "\n",
    "        #4. If only verb here \n",
    "        elif v_pos != -1 and adj_pos == -1 and adv_pos == -1:\n",
    "            target_pos = v_pos\n",
    "            target_word, pos = analyzed_sentence[target_pos]\n",
    "\n",
    "        #Else, return []\n",
    "        else:\n",
    "            return paraphrased_result\n",
    "            \n",
    "    \n",
    "        #find similar onomatopoeia    \n",
    "        similar_onomatope = self.find_similar_onomatope(target_word, top_n=5)\n",
    "   \n",
    "\n",
    "        #choose most similar one\n",
    "        if not similar_onomatope:\n",
    "            return paraphrased_result\n",
    "        \n",
    "        onoma, sim = similar_onomatope[0]\n",
    "\n",
    "        #if the similarity is too low, I would skip\n",
    "        if sim < 0.05:\n",
    "            return paraphrased_result\n",
    "\n",
    "        #find similar onomatope for the target(ind, word, pos)\n",
    "        #switch it to the onomatope\n",
    "        words = [w for w, _ in analyzed_sentence]\n",
    "                \n",
    "        words[target_pos] = onoma\n",
    "\n",
    "        new_sentence = \"\".join(words)\n",
    "        \n",
    "        #return the paraphrased sentence        \n",
    "        paraphrased_result.append({\n",
    "            'original sentence': sentence,\n",
    "            'paraphrased sentence': new_sentence,\n",
    "            'similarity': sim\n",
    "        })\n",
    "\n",
    "\n",
    "        return paraphrased_result\n",
    "    \n",
    "\n",
    "\n",
    "    #'prepare_and_train' method prepare for this whole model and train\n",
    "    #>>> This part does: set onomatope list, prepare training data, train word2vec\n",
    "    def prepare_and_train(self, training_sentences):\n",
    "        \n",
    "        random.seed(42)\n",
    "   \n",
    "\n",
    "        #Word2Vec training data\n",
    "        training_data = self.prepare_data_word2vec(training_sentences, max_sentences=500000)\n",
    "        \n",
    "        #train word2vec\n",
    "        self.train_word2vec(training_data)\n",
    "        \n",
    "        print(\"completed training model\")\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420e0d84-6d2f-43b2-8171-ad97a9590e59",
   "metadata": {},
   "source": [
    "__-How to implement the python code__\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cbb6d8d4-f733-40e9-8e0c-84c2d2c6065c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 302 onomatopoeia from the list\n",
      "Loaded 89 additional onomatopoeia sentences\n",
      "loading corpus data\n",
      "loading corpus dataset, max=100000\n",
      "Loaded 100000 sentences\n",
      "preparing data for word2vec\n",
      "Completed preparation. The number of sentence for word2vec: 100089\n",
      "Training Word2Vec\n",
      "completed training word2vec model with 100089 sentences\n",
      "onomatope in word2vec vocab: 172, onomatope random vector added:130\n",
      "completed training model\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "please input a sentence that you want to paraphrase: 今日はとても忙しい。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original sentence: 今日はとても忙しい。\n",
      "paraphrased sentence: 今日はとてもワイワイ。\n",
      "similarity: 0.7282914\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    #https://www.tufs.ac.jp/common/fs/ilr/contents/ronshuu/26/jilr26_Article_Huang.pdf\n",
    "\n",
    "    #path to onomatope_list\n",
    "    onomatope_path = \"/Users/daikisuematsu/LING539/onomatopoeia-nlp/data/onomatope_list.txt\"\n",
    "    \n",
    "    #path to onomatope_sentences\n",
    "    additional_path = \"/Users/daikisuematsu/LING539/onomatopoeia-nlp/data/onomatope_sentences.txt\"\n",
    "\n",
    "    #prepare paraphraser\n",
    "    paraphraser = OnomatoParaphraser(onomatope_path, additional_path)\n",
    "\n",
    "    \n",
    "    #prepare corpus data for training\n",
    "    print(\"loading corpus data\")\n",
    "    training_sentences = paraphraser.load_dataset(max_sample=100000)\n",
    "\n",
    "    #prepare more training sentences of onomatopoeia for training\n",
    "    training_sentences.extend(paraphraser.additional_onoma_sentences)\n",
    "    \n",
    "    #prepare_and_train(self, onomatope_list, training_sentences):\n",
    "    paraphraser.prepare_and_train(training_sentences)\n",
    "\n",
    "    #input test_sentence\n",
    "    test_sentence = input(\"please input a sentence that you want to paraphrase:\")\n",
    "    results = paraphraser.paraphrase_sentence(test_sentence)\n",
    "       # paraphrased_result.append({\n",
    "        #            'original sentence': sentence,\n",
    "         #           'paraphrased sentence': new_sentence,\n",
    "          #          'similarity': sim\n",
    "           #     })\n",
    "    \n",
    "    if results:\n",
    "        for result in results:\n",
    "            print(\"original sentence:\", result['original sentence'])\n",
    "            print(\"paraphrased sentence:\", result['paraphrased sentence'])\n",
    "            print(\"similarity:\", result['similarity'])\n",
    "    else:\n",
    "        print(\"Failed to paraphrase\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "50893d34-265b-47ff-81c1-09049f505148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 302 onomatopoeia from the list\n",
      "Loaded 89 additional onomatopoeia sentences\n",
      "loading corpus dataset, max=500000\n",
      "Loaded 500000 sentences\n",
      "preparing data for word2vec\n",
      "Completed preparation. The number of sentence for word2vec: 150000\n",
      "Training Word2Vec\n",
      "completed training word2vec model with 150000 sentences\n",
      "onomatope in word2vec vocab: 181, onomatope random vector added:121\n",
      "completed training model\n"
     ]
    }
   ],
   "source": [
    "onomatope_path = \"/Users/daikisuematsu/LING539/onomatopoeia-nlp/data/onomatope_list.txt\"\n",
    "additional_path = \"/Users/daikisuematsu/LING539/onomatopoeia-nlp/data/onomatope_sentences.txt\"\n",
    "\n",
    "paraphraser = OnomatoParaphraser(onomatope_path, additional_path)\n",
    "\n",
    "training_sentences = paraphraser.load_dataset(max_sample=500000)\n",
    "training_sentences.extend(paraphraser.additional_onoma_sentences)\n",
    "\n",
    "paraphraser.prepare_and_train(training_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "423a0299-b7bc-416e-8a17-45dd21d7ed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the word2vec model\n",
    "def test_similarity(paraphraser, top_n=5):\n",
    "\n",
    "    test_word = input(\"please input a word\").strip()\n",
    "\n",
    "    print(f\"Similar onomatopoeia of {test_word}  Top {top_n}：\")\n",
    "    similar = paraphraser.find_similar_onomatope(test_word, top_n=5)\n",
    "\n",
    "    if not similar:\n",
    "        print(\"no words in word2vec\")\n",
    "        return\n",
    "    \n",
    "    for onoma, sim in similar:\n",
    "        print(f\"{onoma}: {sim:.4f}\")\n",
    "        \n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a717c944-e5f2-4a64-b9a3-d7cb8a5aaed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "please input a word 歩きます\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar onomatopoeia of 歩きます  Top 5：\n",
      "'歩きます' is not in the vocabulary.\n",
      "no words in word2vec\n"
     ]
    }
   ],
   "source": [
    "test_similarity(paraphraser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813364a8-aa4f-4078-a327-ebcf7b7f95da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jaconv\n",
    "\n",
    "katakana_text = \"\"\"アタフタ アッサリ アヤフヤ イソイソ イライラ ウキウキ ウジャウジャ \n",
    "        ウダウダ ウッカリ ウッスラ ウットリ ウツラウツラ ウトウト ウロウロ ウンザリ ウント オイオイ オズオズ\n",
    "        オソルオソル オットリ カサカサ ガサガサ カタカタ ガタガタ カチカチ ガチャガチャ ガツガツ \n",
    "        ガッカリ ガックリ ガッチリ カット ガミガミ カラカラ カラット ガラリト カリカリ\n",
    "        ガリガリ カンカン ガンガン ギクシャク ギザギザ ギスギス キチント ギッシリ キッチリ キット キッパリ キビキビ\n",
    "        ギュット ギョット キョロキョロ キラキラ ギラギラ ギリギリ グイグイ グウグウ クシャクシャ グシャグシャ クスクス クタクタ\n",
    "        グチャグチャ クッキリ グツグツ グッスリ グッタリ グット クヨクヨ グラグラ クリクリ クルクル グルグル クルリ\n",
    "        グングン グント ゲッソリ ゲラゲラ ケロット ゲンナリ ゴクゴク ゴシゴシ コソコソ ゴソゴソ ゴタゴタ ゴチャゴチャ\n",
    "        コツコツ ゴツゴツ コッソリ ゴッチャ コッテリ コトコト コロコロ ゴロゴロ ゴワゴワ コンガリ コンコン コンモリ\n",
    "        サクサク ザックバラン ザックリ サッサト サット ザット サッパリ サラサラ ザラザラ ザワザワ シクシク シゲシゲ\n",
    "        シッカリ シックリ ジックリ ジット シットリ シトシト シバシバ ジメジメ シャキシャキ シャックリ シャブシャブ ジャラジャラ\n",
    "        アタフタ アッサリ アヤフヤ イソイソ イライラ ウキウキ ウジャウジャ ウダウダ ウッカリ ウッスラ ウットリ ウツラウツラ\n",
    "        ウトウト ウロウロ ウンザリ ウント オイオイ オズオズ オソルオソル オットリ カサカサ ガサガサ カタカタ ガタガタ\n",
    "        カチカチ ガチャガチャ ガツガツ ガッカリ ガックリ ガッチリ カット ガミガミ カラカラ カラット ガラリト カリカリ\n",
    "        ガリガリ カンカン ガンガン ギクシャク ギザギザ ギスギス キチント ギッシリ キッチリ キット キッパリ キビキビ\n",
    "        ギュット ギョット キョロキョロ キラキラ ギラギラ ギリギリ グイグイ グウグウ クシャクシャ グシャグシャ クスクス クタクタ\n",
    "        グチャグチャ クッキリ グツグツ グッスリ グッタリ グット クヨクヨ グラグラ クリクリ クルクル グルグル クルリ\n",
    "        グングン グント ゲッソリ ゲラゲラ ケロット ゲンナリ ゴクゴク ゴシゴシ コソコソ ゴソゴソ ゴタゴタ ゴチャゴチャ\n",
    "        コツコツ ゴツゴツ コッソリ ゴッチャ コッテリ コトコト コロコロ ゴロゴロ ゴワゴワ コンガリ コンコン コンモリ\n",
    "        サクサク ザックバラン ザックリ サッサト サット ザット サッパリ サラサラ ザラザラ ザワザワ シクシク シゲシゲ\n",
    "        シッカリ シックリ ジックリ ジット シットリ シトシト シバシバ ジメジメ シャキシャキ シャックリ シャブシャブ ジャラジャラ\n",
    "        ホトホト ホノボノ ボヤボヤ ボロボロ ポロポロ ホンノリ ポンポン ボンヤリ マチマチ ムカムカ ムシャクシャ ムッツリ メチャ メチャクチャ\n",
    "        メチャメチャ モクモク モタモタ モリモリ モロモロ ヤキモキ ヤンワリ ユックリ ユッタリ ヨタヨタ ヨチヨチ ヨボヨボ\n",
    "        ヨレヨレ ヨロヨロ ワイワイ ワクワク ワンワン\"\"\"\n",
    "\n",
    "# 単語ごとに分割して変換\n",
    "words = katakana_text.split()\n",
    "hiragana_words = [jaconv.kata2hira(word) for word in words]\n",
    "\n",
    "# 結果表示\n",
    "hiragana_text = \" \".join(hiragana_words)\n",
    "print(hiragana_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "05befee1-c627-4e33-bde0-9dbb74b59032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"不合格の知らせにがっかりとさせられた\", \"仕事がうまくいかなくてがっかりだ\", \"生徒たちががやがやさわいでいる\",\n",
      "\"パーティ会場はがやがやしていた\", \"がやがやした店は好きじゃない\", \"のどがかわいて、からからだ\",\n",
      "\"洗濯物がからからに乾いた\", \"からから天気の日が続く\", \"がらがらとシャッターを開ける\",\n",
      "\"地震でへいががらがらと崩れた\", \"歌いすぎてのどががらがらになった\", \"家に帰ったらすぐ，がらがらとうがいをする\",\n",
      "\"店員ががらがら声で客を呼びこんでいる\", \"がんがん工事をする音が聞こえる\", \"野球のコーチががんがん怒鳴っている\",\n",
      "\"二日酔いで頭ががんがんする\", \"クーラーをがんがんにきかせる\", \"毎日朝ごはんをきちんと食べている\",\n",
      "\"本棚に本をきちんと並べる\", \"家賃を毎月きちんと払う\", \"財布にお札がぎっしりつまっている\",\n",
      "\"今週は予定がぎっしりだ\", \"小さな字でぎっしりと書いてある\", \"家具のサイズをきっちり測る\",\n",
      "\"本棚に本がきっちり入れてある\", \"借りたお金はきっちり返す\", \"セールスの電話はきっぱり断る\",\n",
      "\"今日からたばこはきっぱりやめる\", \"きっぱりとした態度をとる\", \"空の星がきらきら光る\",\n",
      "\"子供は目がきらきらしている\", \"パーティにきらきらの服を着ていく\", \"走っていったらぎりぎり間に合った\",\n",
      "\"合格点ぎりぎりでパスした\", \"ぎりぎりのお金しか持っていかない\", \"締め切りぎりぎりにならないと書き始めない\",\n",
      "\"マンガを読んでくすくすと笑っている\", \"くすくす笑いをしている\", \"ぐずぐずしていると間に合わない\",\n",
      "\"花粉症で鼻がぐずぐずする\", \"きのうの夜は、ぐっすり眠れた\", \"子供がぐっすりと寝ている\",\n",
      "\"最近どうもぐっすり寝られない\", \"重いドアをぐっと押す\", \"泣きたくてもぐっとがまんする\",\n",
      "\"冷たいビールをぐっと飲む\", \"コマがくるくる回る\", \"カレンダーをくるくる丸めた\",\n",
      "\"くるくるに巻いた髪\", \"道に迷ってぐるぐる歩き回った\", \"乗り物がぐるぐる回転する\",\n",
      "\"酔っ払って目がぐるぐる回る\", \"ロープでぐるぐる巻きにする\", \"病気でげっそりとやせた\",\n",
      "\"げっそりした表情で帰ってきた\", \"毎日同じものを食べてげっそりする\", \"漫画を読んでげらげら笑っている\",\n",
      "\"げらげら笑いすぎてお腹が痛くなった\", \"人の失敗をげらげらと笑うのは失礼だ\", \"引き出しの中がごちゃごちゃだ\",\n",
      "\"小さな店がごちゃごちゃと建っている\", \"ごちゃごちゃした模様は好きじゃない\", \"映画のストーリーがごちゃごちゃしてわかりにくい\",\n",
      "\"テーブルの上の料理をこっそり食べた\", \"夜遅くこっそりと家を出た\", \"ピンポン玉がころころところがる\",\n",
      "\"ころころと太った子犬\", \"言うことがころころ変わる\", \"試合にころころ負ける\",\n",
      "\"雷がごろごろなる\", \"猫がごろごろとのどを鳴らす\", \"お腹がごろごろする\",\n",
      "\"荷物がごろごろ転がる\", \"雨がざあざあ降っている\", \"外はざあざあ降りの大雨だ\",\n",
      "\"一人でさっさと帰ってしまった\", \"宿題をさっさと片付ける\", \"５時になったらさっと帰る\",\n",
      "\"テーブルの上をさっと片付ける\", \"雨がさっと降ってすぐやんだ\", \"資料にざっと目を通す\",\n",
      "\"バケツの水をざっとかける\", \"袋に入った米がざっとこぼれた\", \"ざっと計算して100万円はかかる\",\n",
      "\"長い髪をさっぱりと短くした\", \"デザートはさっぱり(と)した果物が食べたい\", \"難しくてさっぱりわからない\",\n",
      "\"髪がさらさらできれいだ\", \"さらさらの粉雪が降りつもっている\", \"さらさらっとサインする\",\n",
      "\"砂がさらさら(と)こぼれる\", \"砂がざらざらと落ちた\", \"風が強い日は，床がざらざらになる\",\n",
      "\"おばあちゃんの手はざらざらだ\", \"家の土台がしっかりしている\", \"子どもが母親にしっかりつかまっている\",\n",
      "\"若いときからしっかり貯金している\", \"しっかりした計画を立てる\", \"将来のことをじっくり考えて決める\",\n",
      "\"じっくり煮込んだシチューを作る\", \"痛くてもじっとがまんする\", \"心配でじっとしていられない\",\n",
      "\"人をじろじろ見るのは失礼だ\", \"店員にじろじろ見られた\", \"薬を飲んですっかり良くなった\",\n",
      "\"宿題のことをすっかり忘れていた\n",
      "もうすっかり一人前の大人だ\", \"部屋を片付けてすっきりした\", \"今朝は、すっきり起きられた\",\n",
      "\"すっきりしたデザインの洋服\", \"冷たいものを飲むとすっとする\", \"音もなくすっと部屋に入ってきた\",\n",
      "\"悪者がつかまって，胸がすっとした\", \"このペンはすらすら書ける\", \"難しい問題をすらすら解いた\",\n",
      "\"駐車場に観光バスがずらりと並んでいる\", \"世界各国のワインをずらりとそろえている\", \"重い荷物をずるずるとひきずる\",\n",
      "\"ずるずると返事をのばしている\", \"悪い仲間とずるずる付き合う\", \"親子で声がそっくりだ\",\n",
      "\"これとそっくりのかばんを持っている\", \"本物とそっくりに作ってある\", \"どろぼうが金庫の中身をそっくり盗んだ\",\n",
      "\"ワイングラスをそっと持つ\", \"うしろの出口からそっと帰る\", \"この問題には触れずにそっとしておこう\",\n",
      "\"もう遅いからそろそろ帰ろう\", \"息子もそろそろ結婚を考える歳になった\", \"足が痛いのでそろそろと歩いている\",\n",
      "\"観光客がぞろぞろ降りてきた\", \"なべにお湯をたっぷり入れる\", \"時間がたっぷりある\",\n",
      "\"たっぷりした服を着る\", \"だぶだぶのズボンが流行する\", \"お腹の肉がだぶだぶしている\",\n",
      "\"食事の前にちゃんと手を洗う\", \"小さな子供たちがちゃんと並んでいる\", \"床がつるつるしていて危ない\",\n",
      "\"つるつるの肌になる\", \"スピーチをするとき、どきどきした\", \"走ったあとは、心臓がどきどきする\",\n",
      "\"テストの点を見るときはいつもどきどきだ\", \"1日中歩き回ってどっと疲れた\", \"電車から人がどっと降りてくる\",\n",
      "\"ドアをどんどんとたたく音がする\", \"祭りの太鼓をどんどんたたく\", \"日本語がどんどん上手になる\",\n",
      "\"駅前にマンションがどんどん建つ\", \"ジャングルの中をどんどん進む\", \"赤ちゃんがにこにこ笑っている\",\n",
      "\"ちえ子さんはいつもにこにこしている\", \"ボーナスをもらってにこにこ顔だ\", \"携帯メールを見ながらにやにやしている\",\n",
      "\"授業中にやにや笑っていて先生に怒られた\", \"急ににやにやした顔になった\", \"プールの底がぬるぬるしている\",\n",
      "\"油がついて，手がぬるぬるすべる\", \"ぬるぬるした海草が気持ち悪い\", \"納豆のねばねばが口につく\",\n",
      "\"ねばねばした食べ物は体にいい\", \"行列がのろのろと進んだ\", \"のろのろしていると遅れるよ\",\n",
      "\"連休で高速道路はどこものろのろ運転だ\", \"温泉に入ってのんびりする\", \"休みの日は、のんびりと過ごしたい\",\n",
      "\"赤ちゃんが手足をばたばたさせる\", \"暑さで人がばたばた倒れる\", \"朝はみんなばたばたと出かけていく\",\n",
      "\"忙しくてばたばたしている\", \"寝不足で頭がはっきりしない\", \"はっきりしない天気が続く\",\n",
      "\"20年前の友人とばったり会った\", \"選手はゴールに入ったとたんばったり（と）倒れた\", \"悪い夢を見てはっと目がさめた\",\n",
      "\"急ブレーキの音がしてはっとした\", \"車内アナウンスにはっとして飛び降りた\", \"ぱっと見て決めた\",\n",
      "\"うわさがぱっと広まる\", \"ボーナスをぱっと使ってしまった\", \"売り上げがぱっとしない\",\n",
      "\"木の葉がはらはらと散る\", \"涙がはらはらと落ちた\", \"人がばらばらと飛び出してきた\",\n",
      "\"家族の食事の時間がばらばらだ\", \"ジグソーパズルをばらばらにする\", \"ばらばら死体が発見された\",\n",
      "\"くつをぴかぴかにみがく\", \"ダイアモンドの指輪がぴかぴか(と)光る\", \"急に大きな音がしてびっくりした\",\n",
      "\"あの人がどろぼうだったとは、びっくりだ\", \"おじいさんから、びっくり箱をもらった\", \"くつのサイズがぴったり合った\",\n",
      "\"子供が母親にぴったりくっついている\", \"体にぴったりした服を着る\", \"パンがふっくらと焼けた\",\n",
      "\"モデルにしてはふっくらした体型だ\", \"ふと後ろを見ると，先生が立っていた\", \"ふとしたことから知り合った\",\n",
      "\"忘れていた用事をふと思い出した\", \"寝不足でふらふらする\", \"酔っ払いがふらふら歩いている\",\n",
      "\"ビデオで撮った画面がふらふら揺れる\", \"悪い友達にふらふらとついていく\", \"ふらふらと遊び歩いている\",\n",
      "\"電気のひもがぶらぶら揺れる\", \"小さな子供が足をぶらぶらさせている\", \"街をぶらぶらと歩く\",\n",
      "\"こわくて足がぶるぶるする\", \"犬がぶるぶるっと体をふるわせた\", \"お腹がすいてぺこぺこだ\",\n",
      "\"電話をかけながら、ぺこぺこ頭を下げる\", \"社長の前ではぺこぺこする\", \"アルミの皿がぺこぺこする\",\n",
      "\"外国語がぺらぺらだ\", \"ぺらぺらよくしゃべる\", \"ページをぺらぺらとめくる\",\n",
      "\"ぺらぺらの紙\", \"頭がぼうっとしてきた\", \"ぼうっとテレビを見ていた\",\n",
      "\"試験に合格してほっとした\", \"手術が無事に終わってほっと安心した\", \"頂上に着いてほっと一息つく\",\n",
      "\"ぼろぼろの辞書を使っている\", \"試合でぼろぼろに負けた\", \"車がぼろぼろだ\",\n",
      "\"彼はぼんやりした人だ\", \"遠くの山がぼんやりと見える\", \"昔のことをぼんやりと覚えている\",\n",
      "\"船酔いで胸がむかむかする\", \"食べ過ぎて胃がむかむかする\", \"弟に負けてむかむかした\",\n",
      "\"Ｂ君の作文はめちゃくちゃだ\", \"地震で家がめちゃくちゃにこわれた\", \"あの店はめちゃくちゃな値段をつけている\",\n",
      "\"Ｔ大学に合格してめちゃくちゃうれしい\", \"男の子たちがもりもり食べている\", \"やる気がもりもりわいてきた\",\n",
      "\"ボディビルの選手は筋肉もりもりだ\", \"もっとゆっくり話してください\", \"川の水がゆっくり流れている\",\n",
      "\"みんなゆっくりしたペースで走っている\", \"おじいさんがよろよろ歩いている\", \"あっちへよろよろ，こっちへよろよろする\",\n",
      "\"ボクサーがよろよろと倒れる\", \"初めて海外旅行に行くのでわくわくする\", \"入学の日をわくわくしながら待っている\",\n",
      "\"『ハリー・ポッター』はわくわくどきどきの映画だ\", \"\",\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "不合格の知らせにがっかりとさせられた。仕事がうまくいかなくてがっかりだ。生徒たちががやがやさわいでいる。\n",
    "パーティ会場はがやがやしていた。がやがやした店は好きじゃない。のどがかわいて、からからだ。\n",
    "洗濯物がからからに乾いた。からから天気の日が続く。がらがらとシャッターを開ける。\n",
    "地震でへいががらがらと崩れた。歌いすぎてのどががらがらになった。家に帰ったらすぐ，がらがらとうがいをする。\n",
    "店員ががらがら声で客を呼びこんでいる。がんがん工事をする音が聞こえる。野球のコーチががんがん怒鳴っている。\n",
    "二日酔いで頭ががんがんする。クーラーをがんがんにきかせる。毎日朝ごはんをきちんと食べている。本棚に本をきちんと並べる。\n",
    "家賃を毎月きちんと払う。財布にお札がぎっしりつまっている。今週は予定がぎっしりだ。\n",
    "小さな字でぎっしりと書いてある。家具のサイズをきっちり測る。本棚に本がきっちり入れてある。\n",
    "借りたお金はきっちり返す。セールスの電話はきっぱり断る。今日からたばこはきっぱりやめる。\n",
    "きっぱりとした態度をとる。空の星がきらきら光る。子供は目がきらきらしている。\n",
    "パーティにきらきらの服を着ていく。走っていったらぎりぎり間に合った。\n",
    "合格点ぎりぎりでパスした。ぎりぎりのお金しか持っていかない。\n",
    "締め切りぎりぎりにならないと書き始めない。マンガを読んでくすくすと笑っている。\n",
    "くすくす笑いをしている。ぐずぐずしていると間に合わない。花粉症で鼻がぐずぐずする。きのうの夜は、ぐっすり眠れた。\n",
    "子供がぐっすりと寝ている。最近どうもぐっすり寝られない。重いドアをぐっと押す。\n",
    "泣きたくてもぐっとがまんする。冷たいビールをぐっと飲む。コマがくるくる回る。カレンダーをくるくる丸めた。\n",
    "くるくるに巻いた髪。道に迷ってぐるぐる歩き回った。\n",
    "乗り物がぐるぐる回転する。酔っ払って目がぐるぐる回る。\n",
    "ロープでぐるぐる巻きにする。病気でげっそりとやせた。\n",
    "げっそりした表情で帰ってきた。\n",
    "毎日同じものを食べてげっそりする。漫画を読んでげらげら笑っている。\n",
    "げらげら笑いすぎてお腹が痛くなった。\n",
    "人の失敗をげらげらと笑うのは失礼だ。引き出しの中がごちゃごちゃだ。\n",
    "小さな店がごちゃごちゃと建っている。\n",
    "ごちゃごちゃした模様は好きじゃない。\n",
    "映画のストーリーがごちゃごちゃしてわかりにくい。テーブルの上の料理をこっそり食べた。\n",
    "夜遅くこっそりと家を出た。ピンポン玉がころころところがる。ころころと太った子犬。\n",
    "言うことがころころ変わる。\n",
    "試合にころころ負ける。雷がごろごろなる。\n",
    "猫がごろごろとのどを鳴らす。\n",
    "お腹がごろごろする。\n",
    "荷物がごろごろ転がる。雨がざあざあ降っている。\n",
    "外はざあざあ降りの大雨だ。一人でさっさと帰ってしまった。\n",
    "宿題をさっさと片付ける。５時になったらさっと帰る。\n",
    "テーブルの上をさっと片付ける。\n",
    "雨がさっと降ってすぐやんだ。資料にざっと目を通す。\n",
    "バケツの水をざっとかける。\n",
    "袋に入った米がざっとこぼれた。\n",
    "ざっと計算して100万円はかかる。長い髪をさっぱりと短くした。\n",
    "デザートはさっぱり(と)した果物が食べたい。\n",
    "難しくてさっぱりわからない。髪がさらさらできれいだ。\n",
    "さらさらの粉雪が降りつもっている。\n",
    "さらさらっとサインする。\n",
    "砂がさらさら(と)こぼれる。砂がざらざらと落ちた。\n",
    "風が強い日は，床がざらざらになる。\n",
    "おばあちゃんの手はざらざらだ。家の土台がしっかりしている。\n",
    "子どもが母親にしっかりつかまっている。\n",
    "若いときからしっかり貯金している。\n",
    "しっかりした計画を立てる。将来のことをじっくり考えて決める。\n",
    "じっくり煮込んだシチューを作る。痛くてもじっとがまんする。\n",
    "心配でじっとしていられない。人をじろじろ見るのは失礼だ。\n",
    "店員にじろじろ見られた。薬を飲んですっかり良くなった。\n",
    "宿題のことをすっかり忘れていた\n",
    "もうすっかり一人前の大人だ。部屋を片付けてすっきりした。\n",
    "今朝は、すっきり起きられた。\n",
    "すっきりしたデザインの洋服。冷たいものを飲むとすっとする。\n",
    "音もなくすっと部屋に入ってきた。\n",
    "悪者がつかまって，胸がすっとした。このペンはすらすら書ける。\n",
    "難しい問題をすらすら解いた。駐車場に観光バスがずらりと並んでいる。\n",
    "世界各国のワインをずらりとそろえている。重い荷物をずるずるとひきずる。\n",
    "ずるずると返事をのばしている。\n",
    "悪い仲間とずるずる付き合う。親子で声がそっくりだ。\n",
    "これとそっくりのかばんを持っている。\n",
    "本物とそっくりに作ってある。\n",
    "どろぼうが金庫の中身をそっくり盗んだ。ワイングラスをそっと持つ。\n",
    "うしろの出口からそっと帰る。\n",
    "この問題には触れずにそっとしておこう。もう遅いからそろそろ帰ろう。\n",
    "息子もそろそろ結婚を考える歳になった。\n",
    "足が痛いのでそろそろと歩いている。観光客がぞろぞろ降りてきた。なべにお湯をたっぷり入れる。\n",
    "時間がたっぷりある。\n",
    "たっぷりした服を着る。だぶだぶのズボンが流行する。\n",
    "お腹の肉がだぶだぶしている。食事の前にちゃんと手を洗う。\n",
    "小さな子供たちがちゃんと並んでいる。床がつるつるしていて危ない。\n",
    "つるつるの肌になる。スピーチをするとき、どきどきした。\n",
    "走ったあとは、心臓がどきどきする。\n",
    "テストの点を見るときはいつもどきどきだ。1日中歩き回ってどっと疲れた。\n",
    "電車から人がどっと降りてくる。ドアをどんどんとたたく音がする。\n",
    "祭りの太鼓をどんどんたたく。\n",
    "日本語がどんどん上手になる。\n",
    "駅前にマンションがどんどん建つ。\n",
    "ジャングルの中をどんどん進む。赤ちゃんがにこにこ笑っている。\n",
    "ちえ子さんはいつもにこにこしている。\n",
    "ボーナスをもらってにこにこ顔だ。携帯メールを見ながらにやにやしている。\n",
    "授業中にやにや笑っていて先生に怒られた。\n",
    "急ににやにやした顔になった。プールの底がぬるぬるしている。\n",
    "油がついて，手がぬるぬるすべる。\n",
    "ぬるぬるした海草が気持ち悪い。納豆のねばねばが口につく。\n",
    "ねばねばした食べ物は体にいい。行列がのろのろと進んだ。\n",
    "のろのろしていると遅れるよ。\n",
    "連休で高速道路はどこものろのろ運転だ。温泉に入ってのんびりする。\n",
    "休みの日は、のんびりと過ごしたい。赤ちゃんが手足をばたばたさせる。\n",
    "暑さで人がばたばた倒れる。\n",
    "朝はみんなばたばたと出かけていく。\n",
    "忙しくてばたばたしている。寝不足で頭がはっきりしない。\n",
    "はっきりしない天気が続く。20年前の友人とばったり会った。\n",
    "選手はゴールに入ったとたんばったり（と）倒れた。悪い夢を見てはっと目がさめた。\n",
    "急ブレーキの音がしてはっとした。\n",
    "車内アナウンスにはっとして飛び降りた。ぱっと見て決めた。\n",
    "うわさがぱっと広まる。\n",
    "ボーナスをぱっと使ってしまった。\n",
    "売り上げがぱっとしない。木の葉がはらはらと散る。\n",
    "涙がはらはらと落ちた。人がばらばらと飛び出してきた。\n",
    "家族の食事の時間がばらばらだ。\n",
    "ジグソーパズルをばらばらにする。\n",
    "ばらばら死体が発見された。くつをぴかぴかにみがく。\n",
    "ダイアモンドの指輪がぴかぴか(と)光る。急に大きな音がしてびっくりした。\n",
    "あの人がどろぼうだったとは、びっくりだ。\n",
    "おじいさんから、びっくり箱をもらった。くつのサイズがぴったり合った。\n",
    "子供が母親にぴったりくっついている。\n",
    "体にぴったりした服を着る。パンがふっくらと焼けた。モデルにしてはふっくらした体型だ。ふと後ろを見ると，先生が立っていた。\n",
    "ふとしたことから知り合った。\n",
    "忘れていた用事をふと思い出した。寝不足でふらふらする。\n",
    "酔っ払いがふらふら歩いている。\n",
    "ビデオで撮った画面がふらふら揺れる。\n",
    "悪い友達にふらふらとついていく。\n",
    "ふらふらと遊び歩いている。電気のひもがぶらぶら揺れる。\n",
    "小さな子供が足をぶらぶらさせている。\n",
    "街をぶらぶらと歩く。こわくて足がぶるぶるする。犬がぶるぶるっと体をふるわせた。お腹がすいてぺこぺこだ。\n",
    "電話をかけながら、ぺこぺこ頭を下げる。\n",
    "社長の前ではぺこぺこする。\n",
    "アルミの皿がぺこぺこする。外国語がぺらぺらだ。\n",
    "ぺらぺらよくしゃべる。ページをぺらぺらとめくる。\n",
    "ぺらぺらの紙。頭がぼうっとしてきた。\n",
    "ぼうっとテレビを見ていた。試験に合格してほっとした。\n",
    "手術が無事に終わってほっと安心した。\n",
    "頂上に着いてほっと一息つく。ぼろぼろの辞書を使っている。\n",
    "試合でぼろぼろに負けた。車がぼろぼろだ。彼はぼんやりした人だ。\n",
    "遠くの山がぼんやりと見える。\n",
    "昔のことをぼんやりと覚えている。船酔いで胸がむかむかする。\n",
    "食べ過ぎて胃がむかむかする。\n",
    "弟に負けてむかむかした。Ｂ君の作文はめちゃくちゃだ。\n",
    "地震で家がめちゃくちゃにこわれた。\n",
    "あの店はめちゃくちゃな値段をつけている。\n",
    "Ｔ大学に合格してめちゃくちゃうれしい。男の子たちがもりもり食べている。\n",
    "やる気がもりもりわいてきた。\n",
    "ボディビルの選手は筋肉もりもりだ。\n",
    "もっとゆっくり話してください。\n",
    "川の水がゆっくり流れている。\n",
    "みんなゆっくりしたペースで走っている。おじいさんがよろよろ歩いている。\n",
    "あっちへよろよろ，こっちへよろよろする。\n",
    "ボクサーがよろよろと倒れる。初めて海外旅行に行くのでわくわくする。\n",
    "入学の日をわくわくしながら待っている。\n",
    "『ハリー・ポッター』はわくわくどきどきの映画だ。\n",
    "\"\"\"\n",
    "\n",
    "lines = text.strip().split(\"。\")\n",
    "quoted_lines = ['\"' + line.strip() + '\",' for line in lines]\n",
    "\n",
    "for i in range(0, len(quoted_lines), 3):\n",
    "    row = quoted_lines[i: i+3]\n",
    "    print(\" \". join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97cb09f-0532-45e6-a30e-34fdfef94947",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "        \"日本料理は味があっさりしている。\", \"こってりした味。\", \"あっさりしたデザインが好きだ。\", \"すっきりしたデザインの服。\", \"兄はあっさりした性格だ。\", \"チャンピオンがあっさりと負けた。\",\n",
    "        \"長い時間待たされていらいらする。\", \"隣の部屋がうるさくていらいらする。\", \"ドライバーのいらいらがつのる。\",\n",
    "        \"試験の点が悪いのは、うっかりミスが多いからだ。\",\"大切な約束をうっかり忘れてしまった。\",\"うっかりして降りる駅を乗り過ごした。\",\n",
    "        \"家の前をうろうろしている人がいる。\",\"クマがうろうろと動き回る。\",\"あっちへうろうろ、こっちへうろうろした。\",\n",
    "        \"宿題が多くてうんざりする。\",\"店長の小言にはもううんざりだ。\",\"乗客はうんざりした顔をしている。\",\n",
    "        \"地震がきて、戸ががたがた揺れた。\",\"古い机なのでがたがたする。\",\"寒くてがたがた震える。\",\n",
    "        \"料理がまずくてがっかりした。\", \"不合格の知らせにがっかりとさせられた\", \"仕事がうまくいかなくてがっかりだ\", \"生徒たちががやがやさわいでいる\",\n",
    "        \"パーティ会場はがやがやしていた\", \"がやがやした店は好きじゃない\", \"のどがかわいて、からからだ\",\n",
    "        \"洗濯物がからからに乾いた\", \"からから天気の日が続く\", \"がらがらとシャッターを開ける\",\n",
    "        \"地震でへいががらがらと崩れた\", \"歌いすぎてのどががらがらになった\", \"家に帰ったらすぐ，がらがらとうがいをする\",\n",
    "        \"店員ががらがら声で客を呼びこんでいる\", \"がんがん工事をする音が聞こえる\", \"野球のコーチががんがん怒鳴っている\",\n",
    "        \"二日酔いで頭ががんがんする\", \"クーラーをがんがんにきかせる\", \"毎日朝ごはんをきちんと食べている\",\n",
    "        \"本棚に本をきちんと並べる\", \"家賃を毎月きちんと払う\", \"財布にお札がぎっしりつまっている\",\n",
    "        \"今週は予定がぎっしりだ\", \"小さな字でぎっしりと書いてある\", \"家具のサイズをきっちり測る\",\n",
    "        \"本棚に本がきっちり入れてある\", \"借りたお金はきっちり返す\", \"セールスの電話はきっぱり断る\",\n",
    "        \"今日からたばこはきっぱりやめる\", \"きっぱりとした態度をとる\", \"空の星がきらきら光る\",\n",
    "        \"子供は目がきらきらしている\", \"パーティにきらきらの服を着ていく\", \"走っていったらぎりぎり間に合った\",\n",
    "        \"合格点ぎりぎりでパスした\", \"ぎりぎりのお金しか持っていかない\", \"締め切りぎりぎりにならないと書き始めない\",\n",
    "        \"マンガを読んでくすくすと笑っている\", \"くすくす笑いをしている\", \"ぐずぐずしていると間に合わない\",\n",
    "        \"花粉症で鼻がぐずぐずする\", \"きのうの夜は、ぐっすり眠れた\", \"子供がぐっすりと寝ている\",\n",
    "        \"最近どうもぐっすり寝られない\", \"重いドアをぐっと押す\", \"泣きたくてもぐっとがまんする\",\n",
    "        \"冷たいビールをぐっと飲む\", \"コマがくるくる回る\", \"カレンダーをくるくる丸めた\",\n",
    "        \"くるくるに巻いた髪\", \"道に迷ってぐるぐる歩き回った\", \"乗り物がぐるぐる回転する\",\n",
    "        \"酔っ払って目がぐるぐる回る\", \"ロープでぐるぐる巻きにする\", \"病気でげっそりとやせた\",\n",
    "        \"げっそりした表情で帰ってきた\", \"毎日同じものを食べてげっそりする\", \"漫画を読んでげらげら笑っている\",\n",
    "        \"げらげら笑いすぎてお腹が痛くなった\", \"人の失敗をげらげらと笑うのは失礼だ\", \"引き出しの中がごちゃごちゃだ\",\n",
    "        \"小さな店がごちゃごちゃと建っている\", \"ごちゃごちゃした模様は好きじゃない\", \"映画のストーリーがごちゃごちゃしてわかりにくい\",\n",
    "        \"テーブルの上の料理をこっそり食べた\", \"夜遅くこっそりと家を出た\", \"ピンポン玉がころころところがる\",\n",
    "        \"ころころと太った子犬\", \"言うことがころころ変わる\", \"試合にころころ負ける\",\n",
    "        \"雷がごろごろなる\", \"猫がごろごろとのどを鳴らす\", \"お腹がごろごろする\",\n",
    "        \"荷物がごろごろ転がる\", \"雨がざあざあ降っている\", \"外はざあざあ降りの大雨だ\",\n",
    "        \"一人でさっさと帰ってしまった\", \"宿題をさっさと片付ける\", \"５時になったらさっと帰る\",\n",
    "        \"テーブルの上をさっと片付ける\", \"雨がさっと降ってすぐやんだ\", \"資料にざっと目を通す\",\n",
    "        \"バケツの水をざっとかける\", \"袋に入った米がざっとこぼれた\", \"ざっと計算して100万円はかかる\",\n",
    "        \"長い髪をさっぱりと短くした\", \"デザートはさっぱり(と)した果物が食べたい\", \"難しくてさっぱりわからない\",\n",
    "        \"髪がさらさらできれいだ\", \"さらさらの粉雪が降りつもっている\", \"さらさらっとサインする\",\n",
    "        \"砂がさらさら(と)こぼれる\", \"砂がざらざらと落ちた\", \"風が強い日は，床がざらざらになる\",\n",
    "        \"おばあちゃんの手はざらざらだ\", \"家の土台がしっかりしている\", \"子どもが母親にしっかりつかまっている\",\n",
    "        \"若いときからしっかり貯金している\", \"しっかりした計画を立てる\", \"将来のことをじっくり考えて決める\",\n",
    "        \"じっくり煮込んだシチューを作る\", \"痛くてもじっとがまんする\", \"心配でじっとしていられない\",\n",
    "        \"人をじろじろ見るのは失礼だ\", \"店員にじろじろ見られた\", \"薬を飲んですっかり良くなった\",\n",
    "        \"宿題のことをすっかり忘れていた\", \"もうすっかり一人前の大人だ\", \"部屋を片付けてすっきりした\", \"今朝は、すっきり起きられた\",\n",
    "        \"すっきりしたデザインの洋服\", \"冷たいものを飲むとすっとする\", \"音もなくすっと部屋に入ってきた\",\n",
    "        \"悪者がつかまって，胸がすっとした\", \"このペンはすらすら書ける\", \"難しい問題をすらすら解いた\",\n",
    "        \"駐車場に観光バスがずらりと並んでいる\", \"世界各国のワインをずらりとそろえている\", \"重い荷物をずるずるとひきずる\",\n",
    "        \"ずるずると返事をのばしている\", \"悪い仲間とずるずる付き合う\", \"親子で声がそっくりだ\",\n",
    "        \"これとそっくりのかばんを持っている\", \"本物とそっくりに作ってある\", \"どろぼうが金庫の中身をそっくり盗んだ\",\n",
    "        \"ワイングラスをそっと持つ\", \"うしろの出口からそっと帰る\", \"この問題には触れずにそっとしておこう\",\n",
    "        \"もう遅いからそろそろ帰ろう\", \"息子もそろそろ結婚を考える歳になった\", \"足が痛いのでそろそろと歩いている\",\n",
    "        \"観光客がぞろぞろ降りてきた\", \"なべにお湯をたっぷり入れる\", \"時間がたっぷりある\",\n",
    "        \"たっぷりした服を着る\", \"だぶだぶのズボンが流行する\", \"お腹の肉がだぶだぶしている\",\n",
    "        \"食事の前にちゃんと手を洗う\", \"小さな子供たちがちゃんと並んでいる\", \"床がつるつるしていて危ない\",\n",
    "        \"つるつるの肌になる\", \"スピーチをするとき、どきどきした\", \"走ったあとは、心臓がどきどきする\",\n",
    "        \"テストの点を見るときはいつもどきどきだ\", \"1日中歩き回ってどっと疲れた\", \"電車から人がどっと降りてくる\",\n",
    "        \"ドアをどんどんとたたく音がする\", \"祭りの太鼓をどんどんたたく\", \"日本語がどんどん上手になる\",\n",
    "        \"駅前にマンションがどんどん建つ\", \"ジャングルの中をどんどん進む\", \"赤ちゃんがにこにこ笑っている\",\n",
    "        \"ちえ子さんはいつもにこにこしている\", \"ボーナスをもらってにこにこ顔だ\", \"携帯メールを見ながらにやにやしている\",\n",
    "        \"授業中にやにや笑っていて先生に怒られた\", \"急ににやにやした顔になった\", \"プールの底がぬるぬるしている\",\n",
    "        \"油がついて，手がぬるぬるすべる\", \"ぬるぬるした海草が気持ち悪い\", \"納豆のねばねばが口につく\",\n",
    "        \"ねばねばした食べ物は体にいい\", \"行列がのろのろと進んだ\", \"のろのろしていると遅れるよ\",\n",
    "        \"連休で高速道路はどこものろのろ運転だ\", \"温泉に入ってのんびりする\", \"休みの日は、のんびりと過ごしたい\",\n",
    "        \"赤ちゃんが手足をばたばたさせる\", \"暑さで人がばたばた倒れる\", \"朝はみんなばたばたと出かけていく\",\n",
    "        \"忙しくてばたばたしている\", \"寝不足で頭がはっきりしない\", \"はっきりしない天気が続く\",\n",
    "        \"20年前の友人とばったり会った\", \"選手はゴールに入ったとたんばったり（と）倒れた\", \"悪い夢を見てはっと目がさめた\",\n",
    "        \"急ブレーキの音がしてはっとした\", \"車内アナウンスにはっとして飛び降りた\", \"ぱっと見て決めた\",\n",
    "        \"うわさがぱっと広まる\", \"ボーナスをぱっと使ってしまった\", \"売り上げがぱっとしない\",\n",
    "        \"木の葉がはらはらと散る\", \"涙がはらはらと落ちた\", \"人がばらばらと飛び出してきた\",\n",
    "        \"家族の食事の時間がばらばらだ\", \"ジグソーパズルをばらばらにする\", \"ばらばら死体が発見された\",\n",
    "        \"くつをぴかぴかにみがく\", \"ダイアモンドの指輪がぴかぴか(と)光る\", \"急に大きな音がしてびっくりした\",\n",
    "        \"あの人がどろぼうだったとは、びっくりだ\", \"おじいさんから、びっくり箱をもらった\", \"くつのサイズがぴったり合った\",\n",
    "        \"子供が母親にぴったりくっついている\", \"体にぴったりした服を着る\", \"パンがふっくらと焼けた\",\n",
    "        \"モデルにしてはふっくらした体型だ\", \"ふと後ろを見ると，先生が立っていた\", \"ふとしたことから知り合った\",\n",
    "        \"忘れていた用事をふと思い出した\", \"寝不足でふらふらする\", \"酔っ払いがふらふら歩いている\",\n",
    "        \"ビデオで撮った画面がふらふら揺れる\", \"悪い友達にふらふらとついていく\", \"ふらふらと遊び歩いている\",\n",
    "        \"電気のひもがぶらぶら揺れる\", \"小さな子供が足をぶらぶらさせている\", \"街をぶらぶらと歩く\",\n",
    "        \"こわくて足がぶるぶるする\", \"犬がぶるぶるっと体をふるわせた\", \"お腹がすいてぺこぺこだ\",\n",
    "        \"電話をかけながら、ぺこぺこ頭を下げる\", \"社長の前ではぺこぺこする\", \"アルミの皿がぺこぺこする\",\n",
    "        \"外国語がぺらぺらだ\", \"ぺらぺらよくしゃべる\", \"ページをぺらぺらとめくる\",\n",
    "        \"ぺらぺらの紙\", \"頭がぼうっとしてきた\", \"ぼうっとテレビを見ていた\",\n",
    "        \"試験に合格してほっとした\", \"手術が無事に終わってほっと安心した\", \"頂上に着いてほっと一息つく\",\n",
    "        \"ぼろぼろの辞書を使っている\", \"試合でぼろぼろに負けた\", \"車がぼろぼろだ\",\n",
    "        \"彼はぼんやりした人だ\", \"遠くの山がぼんやりと見える\", \"昔のことをぼんやりと覚えている\",\n",
    "        \"船酔いで胸がむかむかする\", \"食べ過ぎて胃がむかむかする\", \"弟に負けてむかむかした\",\n",
    "        \"Ｂ君の作文はめちゃくちゃだ\", \"地震で家がめちゃくちゃにこわれた\", \"あの店はめちゃくちゃな値段をつけている\",\n",
    "        \"Ｔ大学に合格してめちゃくちゃうれしい\", \"男の子たちがもりもり食べている\", \"やる気がもりもりわいてきた\",\n",
    "        \"ボディビルの選手は筋肉もりもりだ\", \"もっとゆっくり話してください\", \"川の水がゆっくり流れている\",\n",
    "        \"みんなゆっくりしたペースで走っている\", \"おじいさんがよろよろ歩いている\", \"あっちへよろよろ，こっちへよろよろする\",\n",
    "        \"ボクサーがよろよろと倒れる\", \"初めて海外旅行に行くのでわくわくする\", \"入学の日をわくわくしながら待っている\",\n",
    "        \"『ハリー・ポッター』はわくわくどきどきの映画だ\", \n",
    "        ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(onomato-env)",
   "language": "python",
   "name": "onomato-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
